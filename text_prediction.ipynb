{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEdv9vO1rfi4muHqA+aRv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skhazaei/TensorFlow-repo/blob/master/text_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gu6zCYk9Y6H"
      },
      "source": [
        "##Generate new text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucb7_GU7oPaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1a4cd3-9d83-4121-decd-afb122b0ee59"
      },
      "source": [
        "## the data is an irish song\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "print(data)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the town of Athy one Jeremy Lanigan \n",
            " Battered away til he hadnt a pound. \n",
            "His father died and made him a man again \n",
            " Left him a farm and ten acres of ground. \n",
            "He gave a grand party for friends and relations \n",
            "Who didnt forget him when come to the wall, \n",
            "And if youll but listen Ill make your eyes glisten \n",
            "Of the rows and the ructions of Lanigans Ball. \n",
            "Myself to be sure got free invitation, \n",
            "For all the nice girls and boys I might ask, \n",
            "And just in a minute both friends and relations \n",
            "Were dancing round merry as bees round a cask. \n",
            "Judy ODaly, that nice little milliner, \n",
            "She tipped me a wink for to give her a call, \n",
            "And I soon arrived with Peggy McGilligan \n",
            "Just in time for Lanigans Ball. \n",
            "There were lashings of punch and wine for the ladies, \n",
            "Potatoes and cakes; there was bacon and tea, \n",
            "There were the Nolans, Dolans, OGradys \n",
            "Courting the girls and dancing away. \n",
            "Songs they went round as plenty as water, \n",
            "The harp that once sounded in Taras old hall,\n",
            "Sweet Nelly Gray and The Rat Catchers Daughter,\n",
            "All singing together at Lanigans Ball. \n",
            "They were doing all kinds of nonsensical polkas \n",
            "All round the room in a whirligig. \n",
            "Julia and I, we banished their nonsense \n",
            "And tipped them the twist of a reel and a jig. \n",
            "Ach mavrone, how the girls got all mad at me \n",
            "Danced til youd think the ceiling would fall. \n",
            "For I spent three weeks at Brooks Academy \n",
            "Learning new steps for Lanigans Ball. \n",
            "Three long weeks I spent up in Dublin, \n",
            "Three long weeks to learn nothing at all,\n",
            " Three long weeks I spent up in Dublin, \n",
            "Learning new steps for Lanigans Ball. \n",
            "She stepped out and I stepped in again, \n",
            "I stepped out and she stepped in again, \n",
            "She stepped out and I stepped in again, \n",
            "Learning new steps for Lanigans Ball. \n",
            "Boys were all merry and the girls they were hearty \n",
            "And danced all around in couples and groups, \n",
            "Til an accident happened, young Terrance McCarthy \n",
            "Put his right leg through miss Finnertys hoops. \n",
            "Poor creature fainted and cried Meelia murther, \n",
            "Called for her brothers and gathered them all. \n",
            "Carmody swore that hed go no further \n",
            "Til he had satisfaction at Lanigans Ball. \n",
            "In the midst of the row miss Kerrigan fainted, \n",
            "Her cheeks at the same time as red as a rose. \n",
            "Some of the lads declared she was painted, \n",
            "She took a small drop too much, I suppose. \n",
            "Her sweetheart, Ned Morgan, so powerful and able, \n",
            "When he saw his fair colleen stretched out by the wall, \n",
            "Tore the left leg from under the table \n",
            "And smashed all the Chaneys at Lanigans Ball. \n",
            "Boys, oh boys, twas then there were runctions. \n",
            "Myself got a lick from big Phelim McHugh. \n",
            "I soon replied to his introduction \n",
            "And kicked up a terrible hullabaloo. \n",
            "Old Casey, the piper, was near being strangled. \n",
            "They squeezed up his pipes, bellows, chanters and all. \n",
            "The girls, in their ribbons, they got all entangled \n",
            "And that put an end to Lanigans Ball.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk4BMr8892Pf"
      },
      "source": [
        "## Let's generate a python list of sentences from the `data` and convert all to the lowercases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLiRM-TPozem",
        "outputId": "cf2f749b-4b74-4f10-b3b1-ad9da31895f4"
      },
      "source": [
        "corpus = data.lower().split('\\n')\n",
        "print('first sentence: {}'.format(corpus[0]))\n",
        "print('second sentence: {}'.format(corpus[1]))\n",
        "print('corpus size: {}'.format(len(corpus)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first sentence: in the town of athy one jeremy lanigan \n",
            "second sentence:  battered away til he hadnt a pound. \n",
            "corpus size: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSR92y-n-8r5"
      },
      "source": [
        "## Using `Tokenizer`, create a dictionary of words from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2RYE4fwo7Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d41df67-20a3-41f2-d735-edb186e187e4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "print('A dictionary of the words in the corpus:\\n {}'.format(word_index))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A dictionary of the words in the corpus:\n",
            " {'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VQeBOMvpGST",
        "outputId": "a8cde810-b63d-4766-f466-d7d24c56e236"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index)+1\n",
        "print('total number of words in the dicionary, including out of vocabulary word: {}'.format(total_words))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of words in the dicionary, including out of vocabulary word: 263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM_MboY1A3ax"
      },
      "source": [
        "## Generate training data from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIrPeK-ppb-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882a59a1-81f8-4f3e-98ca-f50c61749a9b"
      },
      "source": [
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  print(token_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 2, 66, 8, 67, 68, 69, 70]\n",
            "[71, 40, 20, 21, 72, 3, 73]\n",
            "[16, 74, 75, 1, 76, 33, 3, 77, 22]\n",
            "[41, 33, 3, 78, 1, 79, 80, 8, 81]\n",
            "[21, 82, 3, 83, 84, 7, 42, 1, 43]\n",
            "[85, 86, 87, 33, 44, 88, 13, 2, 45]\n",
            "[1, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
            "[8, 2, 98, 1, 2, 99, 8, 9, 10]\n",
            "[46, 13, 100, 101, 23, 102, 103]\n",
            "[7, 5, 2, 47, 17, 1, 24, 6, 104, 105]\n",
            "[1, 48, 4, 3, 106, 107, 42, 1, 43]\n",
            "[11, 49, 25, 50, 18, 108, 25, 3, 109]\n",
            "[110, 111, 26, 47, 112, 113]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116]\n",
            "[1, 6, 53, 117, 118, 119, 120]\n",
            "[48, 4, 54, 7, 9, 10]\n",
            "[28, 11, 121, 8, 122, 1, 123, 7, 2, 124]\n",
            "[125, 1, 126, 28, 34, 127, 1, 128]\n",
            "[28, 11, 2, 129, 130, 131]\n",
            "[132, 2, 17, 1, 49, 40]\n",
            "[133, 19, 134, 25, 18, 135, 18, 136]\n",
            "[2, 137, 26, 138, 139, 4, 140, 55, 141]\n",
            "[142, 143, 144, 1, 2, 145, 146, 147]\n",
            "[5, 148, 149, 12, 9, 10]\n",
            "[19, 11, 150, 5, 151, 8, 152, 153]\n",
            "[5, 25, 2, 154, 4, 3, 155]\n",
            "[156, 1, 6, 157, 158, 56, 159]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162]\n",
            "[163, 164, 165, 2, 17, 23, 5, 166, 12, 52]\n",
            "[58, 20, 167, 168, 2, 169, 170, 171]\n",
            "[7, 6, 35, 29, 30, 12, 172, 173]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[29, 39, 30, 13, 174, 175, 12, 5]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[6, 15, 32, 1, 14, 15, 4, 22]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[24, 11, 5, 50, 1, 2, 17, 19, 11, 176]\n",
            "[1, 58, 5, 177, 4, 178, 1, 179]\n",
            "[20, 60, 180, 181, 182, 183, 184]\n",
            "[61, 16, 185, 62, 186, 63, 187, 188]\n",
            "[189, 190, 64, 1, 191, 192, 193]\n",
            "[194, 7, 27, 195, 1, 196, 57, 5]\n",
            "[197, 198, 26, 199, 200, 201, 202]\n",
            "[20, 21, 203, 204, 12, 9, 10]\n",
            "[4, 2, 205, 8, 2, 206, 63, 207, 64]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211]\n",
            "[212, 8, 2, 213, 214, 14, 34, 215]\n",
            "[14, 216, 3, 217, 218, 219, 220, 6, 221]\n",
            "[27, 222, 223, 224, 225, 226, 1, 227]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45]\n",
            "[233, 2, 41, 62, 65, 234, 2, 235]\n",
            "[1, 236, 5, 2, 237, 12, 9, 10]\n",
            "[24, 238, 24, 239, 240, 28, 11, 241]\n",
            "[46, 23, 3, 242, 65, 243, 244, 245]\n",
            "[6, 53, 246, 13, 16, 247]\n",
            "[1, 248, 31, 3, 249, 250]\n",
            "[55, 251, 2, 252, 34, 253, 254, 255]\n",
            "[19, 256, 31, 16, 257, 258, 259, 1, 5]\n",
            "[2, 17, 4, 56, 260, 19, 23, 5, 261]\n",
            "[1, 26, 61, 60, 262, 13, 9, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcIevhzXBkT1",
        "outputId": "c6effaf6-ad52-4108-8275-207960bce440"
      },
      "source": [
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)+1):\n",
        "    sub_seq = token_list[:i+1]\n",
        "    print(sub_seq)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 2]\n",
            "[4, 2, 66]\n",
            "[4, 2, 66, 8]\n",
            "[4, 2, 66, 8, 67]\n",
            "[4, 2, 66, 8, 67, 68]\n",
            "[4, 2, 66, 8, 67, 68, 69]\n",
            "[4, 2, 66, 8, 67, 68, 69, 70]\n",
            "[4, 2, 66, 8, 67, 68, 69, 70]\n",
            "[71, 40]\n",
            "[71, 40, 20]\n",
            "[71, 40, 20, 21]\n",
            "[71, 40, 20, 21, 72]\n",
            "[71, 40, 20, 21, 72, 3]\n",
            "[71, 40, 20, 21, 72, 3, 73]\n",
            "[71, 40, 20, 21, 72, 3, 73]\n",
            "[16, 74]\n",
            "[16, 74, 75]\n",
            "[16, 74, 75, 1]\n",
            "[16, 74, 75, 1, 76]\n",
            "[16, 74, 75, 1, 76, 33]\n",
            "[16, 74, 75, 1, 76, 33, 3]\n",
            "[16, 74, 75, 1, 76, 33, 3, 77]\n",
            "[16, 74, 75, 1, 76, 33, 3, 77, 22]\n",
            "[16, 74, 75, 1, 76, 33, 3, 77, 22]\n",
            "[41, 33]\n",
            "[41, 33, 3]\n",
            "[41, 33, 3, 78]\n",
            "[41, 33, 3, 78, 1]\n",
            "[41, 33, 3, 78, 1, 79]\n",
            "[41, 33, 3, 78, 1, 79, 80]\n",
            "[41, 33, 3, 78, 1, 79, 80, 8]\n",
            "[41, 33, 3, 78, 1, 79, 80, 8, 81]\n",
            "[41, 33, 3, 78, 1, 79, 80, 8, 81]\n",
            "[21, 82]\n",
            "[21, 82, 3]\n",
            "[21, 82, 3, 83]\n",
            "[21, 82, 3, 83, 84]\n",
            "[21, 82, 3, 83, 84, 7]\n",
            "[21, 82, 3, 83, 84, 7, 42]\n",
            "[21, 82, 3, 83, 84, 7, 42, 1]\n",
            "[21, 82, 3, 83, 84, 7, 42, 1, 43]\n",
            "[21, 82, 3, 83, 84, 7, 42, 1, 43]\n",
            "[85, 86]\n",
            "[85, 86, 87]\n",
            "[85, 86, 87, 33]\n",
            "[85, 86, 87, 33, 44]\n",
            "[85, 86, 87, 33, 44, 88]\n",
            "[85, 86, 87, 33, 44, 88, 13]\n",
            "[85, 86, 87, 33, 44, 88, 13, 2]\n",
            "[85, 86, 87, 33, 44, 88, 13, 2, 45]\n",
            "[85, 86, 87, 33, 44, 88, 13, 2, 45]\n",
            "[1, 89]\n",
            "[1, 89, 90]\n",
            "[1, 89, 90, 91]\n",
            "[1, 89, 90, 91, 92]\n",
            "[1, 89, 90, 91, 92, 93]\n",
            "[1, 89, 90, 91, 92, 93, 94]\n",
            "[1, 89, 90, 91, 92, 93, 94, 95]\n",
            "[1, 89, 90, 91, 92, 93, 94, 95, 96]\n",
            "[1, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
            "[1, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
            "[8, 2]\n",
            "[8, 2, 98]\n",
            "[8, 2, 98, 1]\n",
            "[8, 2, 98, 1, 2]\n",
            "[8, 2, 98, 1, 2, 99]\n",
            "[8, 2, 98, 1, 2, 99, 8]\n",
            "[8, 2, 98, 1, 2, 99, 8, 9]\n",
            "[8, 2, 98, 1, 2, 99, 8, 9, 10]\n",
            "[8, 2, 98, 1, 2, 99, 8, 9, 10]\n",
            "[46, 13]\n",
            "[46, 13, 100]\n",
            "[46, 13, 100, 101]\n",
            "[46, 13, 100, 101, 23]\n",
            "[46, 13, 100, 101, 23, 102]\n",
            "[46, 13, 100, 101, 23, 102, 103]\n",
            "[46, 13, 100, 101, 23, 102, 103]\n",
            "[7, 5]\n",
            "[7, 5, 2]\n",
            "[7, 5, 2, 47]\n",
            "[7, 5, 2, 47, 17]\n",
            "[7, 5, 2, 47, 17, 1]\n",
            "[7, 5, 2, 47, 17, 1, 24]\n",
            "[7, 5, 2, 47, 17, 1, 24, 6]\n",
            "[7, 5, 2, 47, 17, 1, 24, 6, 104]\n",
            "[7, 5, 2, 47, 17, 1, 24, 6, 104, 105]\n",
            "[7, 5, 2, 47, 17, 1, 24, 6, 104, 105]\n",
            "[1, 48]\n",
            "[1, 48, 4]\n",
            "[1, 48, 4, 3]\n",
            "[1, 48, 4, 3, 106]\n",
            "[1, 48, 4, 3, 106, 107]\n",
            "[1, 48, 4, 3, 106, 107, 42]\n",
            "[1, 48, 4, 3, 106, 107, 42, 1]\n",
            "[1, 48, 4, 3, 106, 107, 42, 1, 43]\n",
            "[1, 48, 4, 3, 106, 107, 42, 1, 43]\n",
            "[11, 49]\n",
            "[11, 49, 25]\n",
            "[11, 49, 25, 50]\n",
            "[11, 49, 25, 50, 18]\n",
            "[11, 49, 25, 50, 18, 108]\n",
            "[11, 49, 25, 50, 18, 108, 25]\n",
            "[11, 49, 25, 50, 18, 108, 25, 3]\n",
            "[11, 49, 25, 50, 18, 108, 25, 3, 109]\n",
            "[11, 49, 25, 50, 18, 108, 25, 3, 109]\n",
            "[110, 111]\n",
            "[110, 111, 26]\n",
            "[110, 111, 26, 47]\n",
            "[110, 111, 26, 47, 112]\n",
            "[110, 111, 26, 47, 112, 113]\n",
            "[110, 111, 26, 47, 112, 113]\n",
            "[14, 51]\n",
            "[14, 51, 52]\n",
            "[14, 51, 52, 3]\n",
            "[14, 51, 52, 3, 114]\n",
            "[14, 51, 52, 3, 114, 7]\n",
            "[14, 51, 52, 3, 114, 7, 13]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115, 27]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115, 27, 3]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116]\n",
            "[14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116]\n",
            "[1, 6]\n",
            "[1, 6, 53]\n",
            "[1, 6, 53, 117]\n",
            "[1, 6, 53, 117, 118]\n",
            "[1, 6, 53, 117, 118, 119]\n",
            "[1, 6, 53, 117, 118, 119, 120]\n",
            "[1, 6, 53, 117, 118, 119, 120]\n",
            "[48, 4]\n",
            "[48, 4, 54]\n",
            "[48, 4, 54, 7]\n",
            "[48, 4, 54, 7, 9]\n",
            "[48, 4, 54, 7, 9, 10]\n",
            "[48, 4, 54, 7, 9, 10]\n",
            "[28, 11]\n",
            "[28, 11, 121]\n",
            "[28, 11, 121, 8]\n",
            "[28, 11, 121, 8, 122]\n",
            "[28, 11, 121, 8, 122, 1]\n",
            "[28, 11, 121, 8, 122, 1, 123]\n",
            "[28, 11, 121, 8, 122, 1, 123, 7]\n",
            "[28, 11, 121, 8, 122, 1, 123, 7, 2]\n",
            "[28, 11, 121, 8, 122, 1, 123, 7, 2, 124]\n",
            "[28, 11, 121, 8, 122, 1, 123, 7, 2, 124]\n",
            "[125, 1]\n",
            "[125, 1, 126]\n",
            "[125, 1, 126, 28]\n",
            "[125, 1, 126, 28, 34]\n",
            "[125, 1, 126, 28, 34, 127]\n",
            "[125, 1, 126, 28, 34, 127, 1]\n",
            "[125, 1, 126, 28, 34, 127, 1, 128]\n",
            "[125, 1, 126, 28, 34, 127, 1, 128]\n",
            "[28, 11]\n",
            "[28, 11, 2]\n",
            "[28, 11, 2, 129]\n",
            "[28, 11, 2, 129, 130]\n",
            "[28, 11, 2, 129, 130, 131]\n",
            "[28, 11, 2, 129, 130, 131]\n",
            "[132, 2]\n",
            "[132, 2, 17]\n",
            "[132, 2, 17, 1]\n",
            "[132, 2, 17, 1, 49]\n",
            "[132, 2, 17, 1, 49, 40]\n",
            "[132, 2, 17, 1, 49, 40]\n",
            "[133, 19]\n",
            "[133, 19, 134]\n",
            "[133, 19, 134, 25]\n",
            "[133, 19, 134, 25, 18]\n",
            "[133, 19, 134, 25, 18, 135]\n",
            "[133, 19, 134, 25, 18, 135, 18]\n",
            "[133, 19, 134, 25, 18, 135, 18, 136]\n",
            "[133, 19, 134, 25, 18, 135, 18, 136]\n",
            "[2, 137]\n",
            "[2, 137, 26]\n",
            "[2, 137, 26, 138]\n",
            "[2, 137, 26, 138, 139]\n",
            "[2, 137, 26, 138, 139, 4]\n",
            "[2, 137, 26, 138, 139, 4, 140]\n",
            "[2, 137, 26, 138, 139, 4, 140, 55]\n",
            "[2, 137, 26, 138, 139, 4, 140, 55, 141]\n",
            "[2, 137, 26, 138, 139, 4, 140, 55, 141]\n",
            "[142, 143]\n",
            "[142, 143, 144]\n",
            "[142, 143, 144, 1]\n",
            "[142, 143, 144, 1, 2]\n",
            "[142, 143, 144, 1, 2, 145]\n",
            "[142, 143, 144, 1, 2, 145, 146]\n",
            "[142, 143, 144, 1, 2, 145, 146, 147]\n",
            "[142, 143, 144, 1, 2, 145, 146, 147]\n",
            "[5, 148]\n",
            "[5, 148, 149]\n",
            "[5, 148, 149, 12]\n",
            "[5, 148, 149, 12, 9]\n",
            "[5, 148, 149, 12, 9, 10]\n",
            "[5, 148, 149, 12, 9, 10]\n",
            "[19, 11]\n",
            "[19, 11, 150]\n",
            "[19, 11, 150, 5]\n",
            "[19, 11, 150, 5, 151]\n",
            "[19, 11, 150, 5, 151, 8]\n",
            "[19, 11, 150, 5, 151, 8, 152]\n",
            "[19, 11, 150, 5, 151, 8, 152, 153]\n",
            "[19, 11, 150, 5, 151, 8, 152, 153]\n",
            "[5, 25]\n",
            "[5, 25, 2]\n",
            "[5, 25, 2, 154]\n",
            "[5, 25, 2, 154, 4]\n",
            "[5, 25, 2, 154, 4, 3]\n",
            "[5, 25, 2, 154, 4, 3, 155]\n",
            "[5, 25, 2, 154, 4, 3, 155]\n",
            "[156, 1]\n",
            "[156, 1, 6]\n",
            "[156, 1, 6, 157]\n",
            "[156, 1, 6, 157, 158]\n",
            "[156, 1, 6, 157, 158, 56]\n",
            "[156, 1, 6, 157, 158, 56, 159]\n",
            "[156, 1, 6, 157, 158, 56, 159]\n",
            "[1, 51]\n",
            "[1, 51, 57]\n",
            "[1, 51, 57, 2]\n",
            "[1, 51, 57, 2, 160]\n",
            "[1, 51, 57, 2, 160, 8]\n",
            "[1, 51, 57, 2, 160, 8, 3]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161, 1]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161, 1, 3]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162]\n",
            "[1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162]\n",
            "[163, 164]\n",
            "[163, 164, 165]\n",
            "[163, 164, 165, 2]\n",
            "[163, 164, 165, 2, 17]\n",
            "[163, 164, 165, 2, 17, 23]\n",
            "[163, 164, 165, 2, 17, 23, 5]\n",
            "[163, 164, 165, 2, 17, 23, 5, 166]\n",
            "[163, 164, 165, 2, 17, 23, 5, 166, 12]\n",
            "[163, 164, 165, 2, 17, 23, 5, 166, 12, 52]\n",
            "[163, 164, 165, 2, 17, 23, 5, 166, 12, 52]\n",
            "[58, 20]\n",
            "[58, 20, 167]\n",
            "[58, 20, 167, 168]\n",
            "[58, 20, 167, 168, 2]\n",
            "[58, 20, 167, 168, 2, 169]\n",
            "[58, 20, 167, 168, 2, 169, 170]\n",
            "[58, 20, 167, 168, 2, 169, 170, 171]\n",
            "[58, 20, 167, 168, 2, 169, 170, 171]\n",
            "[7, 6]\n",
            "[7, 6, 35]\n",
            "[7, 6, 35, 29]\n",
            "[7, 6, 35, 29, 30]\n",
            "[7, 6, 35, 29, 30, 12]\n",
            "[7, 6, 35, 29, 30, 12, 172]\n",
            "[7, 6, 35, 29, 30, 12, 172, 173]\n",
            "[7, 6, 35, 29, 30, 12, 172, 173]\n",
            "[36, 37]\n",
            "[36, 37, 38]\n",
            "[36, 37, 38, 7]\n",
            "[36, 37, 38, 7, 9]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[29, 39]\n",
            "[29, 39, 30]\n",
            "[29, 39, 30, 6]\n",
            "[29, 39, 30, 6, 35]\n",
            "[29, 39, 30, 6, 35, 31]\n",
            "[29, 39, 30, 6, 35, 31, 4]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[29, 39]\n",
            "[29, 39, 30]\n",
            "[29, 39, 30, 13]\n",
            "[29, 39, 30, 13, 174]\n",
            "[29, 39, 30, 13, 174, 175]\n",
            "[29, 39, 30, 13, 174, 175, 12]\n",
            "[29, 39, 30, 13, 174, 175, 12, 5]\n",
            "[29, 39, 30, 13, 174, 175, 12, 5]\n",
            "[29, 39]\n",
            "[29, 39, 30]\n",
            "[29, 39, 30, 6]\n",
            "[29, 39, 30, 6, 35]\n",
            "[29, 39, 30, 6, 35, 31]\n",
            "[29, 39, 30, 6, 35, 31, 4]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[29, 39, 30, 6, 35, 31, 4, 59]\n",
            "[36, 37]\n",
            "[36, 37, 38]\n",
            "[36, 37, 38, 7]\n",
            "[36, 37, 38, 7, 9]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[14, 15]\n",
            "[14, 15, 32]\n",
            "[14, 15, 32, 1]\n",
            "[14, 15, 32, 1, 6]\n",
            "[14, 15, 32, 1, 6, 15]\n",
            "[14, 15, 32, 1, 6, 15, 4]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[6, 15]\n",
            "[6, 15, 32]\n",
            "[6, 15, 32, 1]\n",
            "[6, 15, 32, 1, 14]\n",
            "[6, 15, 32, 1, 14, 15]\n",
            "[6, 15, 32, 1, 14, 15, 4]\n",
            "[6, 15, 32, 1, 14, 15, 4, 22]\n",
            "[6, 15, 32, 1, 14, 15, 4, 22]\n",
            "[14, 15]\n",
            "[14, 15, 32]\n",
            "[14, 15, 32, 1]\n",
            "[14, 15, 32, 1, 6]\n",
            "[14, 15, 32, 1, 6, 15]\n",
            "[14, 15, 32, 1, 6, 15, 4]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[14, 15, 32, 1, 6, 15, 4, 22]\n",
            "[36, 37]\n",
            "[36, 37, 38]\n",
            "[36, 37, 38, 7]\n",
            "[36, 37, 38, 7, 9]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[36, 37, 38, 7, 9, 10]\n",
            "[24, 11]\n",
            "[24, 11, 5]\n",
            "[24, 11, 5, 50]\n",
            "[24, 11, 5, 50, 1]\n",
            "[24, 11, 5, 50, 1, 2]\n",
            "[24, 11, 5, 50, 1, 2, 17]\n",
            "[24, 11, 5, 50, 1, 2, 17, 19]\n",
            "[24, 11, 5, 50, 1, 2, 17, 19, 11]\n",
            "[24, 11, 5, 50, 1, 2, 17, 19, 11, 176]\n",
            "[24, 11, 5, 50, 1, 2, 17, 19, 11, 176]\n",
            "[1, 58]\n",
            "[1, 58, 5]\n",
            "[1, 58, 5, 177]\n",
            "[1, 58, 5, 177, 4]\n",
            "[1, 58, 5, 177, 4, 178]\n",
            "[1, 58, 5, 177, 4, 178, 1]\n",
            "[1, 58, 5, 177, 4, 178, 1, 179]\n",
            "[1, 58, 5, 177, 4, 178, 1, 179]\n",
            "[20, 60]\n",
            "[20, 60, 180]\n",
            "[20, 60, 180, 181]\n",
            "[20, 60, 180, 181, 182]\n",
            "[20, 60, 180, 181, 182, 183]\n",
            "[20, 60, 180, 181, 182, 183, 184]\n",
            "[20, 60, 180, 181, 182, 183, 184]\n",
            "[61, 16]\n",
            "[61, 16, 185]\n",
            "[61, 16, 185, 62]\n",
            "[61, 16, 185, 62, 186]\n",
            "[61, 16, 185, 62, 186, 63]\n",
            "[61, 16, 185, 62, 186, 63, 187]\n",
            "[61, 16, 185, 62, 186, 63, 187, 188]\n",
            "[61, 16, 185, 62, 186, 63, 187, 188]\n",
            "[189, 190]\n",
            "[189, 190, 64]\n",
            "[189, 190, 64, 1]\n",
            "[189, 190, 64, 1, 191]\n",
            "[189, 190, 64, 1, 191, 192]\n",
            "[189, 190, 64, 1, 191, 192, 193]\n",
            "[189, 190, 64, 1, 191, 192, 193]\n",
            "[194, 7]\n",
            "[194, 7, 27]\n",
            "[194, 7, 27, 195]\n",
            "[194, 7, 27, 195, 1]\n",
            "[194, 7, 27, 195, 1, 196]\n",
            "[194, 7, 27, 195, 1, 196, 57]\n",
            "[194, 7, 27, 195, 1, 196, 57, 5]\n",
            "[194, 7, 27, 195, 1, 196, 57, 5]\n",
            "[197, 198]\n",
            "[197, 198, 26]\n",
            "[197, 198, 26, 199]\n",
            "[197, 198, 26, 199, 200]\n",
            "[197, 198, 26, 199, 200, 201]\n",
            "[197, 198, 26, 199, 200, 201, 202]\n",
            "[197, 198, 26, 199, 200, 201, 202]\n",
            "[20, 21]\n",
            "[20, 21, 203]\n",
            "[20, 21, 203, 204]\n",
            "[20, 21, 203, 204, 12]\n",
            "[20, 21, 203, 204, 12, 9]\n",
            "[20, 21, 203, 204, 12, 9, 10]\n",
            "[20, 21, 203, 204, 12, 9, 10]\n",
            "[4, 2]\n",
            "[4, 2, 205]\n",
            "[4, 2, 205, 8]\n",
            "[4, 2, 205, 8, 2]\n",
            "[4, 2, 205, 8, 2, 206]\n",
            "[4, 2, 205, 8, 2, 206, 63]\n",
            "[4, 2, 205, 8, 2, 206, 63, 207]\n",
            "[4, 2, 205, 8, 2, 206, 63, 207, 64]\n",
            "[4, 2, 205, 8, 2, 206, 63, 207, 64]\n",
            "[27, 208]\n",
            "[27, 208, 12]\n",
            "[27, 208, 12, 2]\n",
            "[27, 208, 12, 2, 209]\n",
            "[27, 208, 12, 2, 209, 54]\n",
            "[27, 208, 12, 2, 209, 54, 18]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210, 18]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210, 18, 3]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211]\n",
            "[27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211]\n",
            "[212, 8]\n",
            "[212, 8, 2]\n",
            "[212, 8, 2, 213]\n",
            "[212, 8, 2, 213, 214]\n",
            "[212, 8, 2, 213, 214, 14]\n",
            "[212, 8, 2, 213, 214, 14, 34]\n",
            "[212, 8, 2, 213, 214, 14, 34, 215]\n",
            "[212, 8, 2, 213, 214, 14, 34, 215]\n",
            "[14, 216]\n",
            "[14, 216, 3]\n",
            "[14, 216, 3, 217]\n",
            "[14, 216, 3, 217, 218]\n",
            "[14, 216, 3, 217, 218, 219]\n",
            "[14, 216, 3, 217, 218, 219, 220]\n",
            "[14, 216, 3, 217, 218, 219, 220, 6]\n",
            "[14, 216, 3, 217, 218, 219, 220, 6, 221]\n",
            "[14, 216, 3, 217, 218, 219, 220, 6, 221]\n",
            "[27, 222]\n",
            "[27, 222, 223]\n",
            "[27, 222, 223, 224]\n",
            "[27, 222, 223, 224, 225]\n",
            "[27, 222, 223, 224, 225, 226]\n",
            "[27, 222, 223, 224, 225, 226, 1]\n",
            "[27, 222, 223, 224, 225, 226, 1, 227]\n",
            "[27, 222, 223, 224, 225, 226, 1, 227]\n",
            "[44, 21]\n",
            "[44, 21, 228]\n",
            "[44, 21, 228, 16]\n",
            "[44, 21, 228, 16, 229]\n",
            "[44, 21, 228, 16, 229, 230]\n",
            "[44, 21, 228, 16, 229, 230, 231]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32, 232]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32, 232, 2]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45]\n",
            "[44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45]\n",
            "[233, 2]\n",
            "[233, 2, 41]\n",
            "[233, 2, 41, 62]\n",
            "[233, 2, 41, 62, 65]\n",
            "[233, 2, 41, 62, 65, 234]\n",
            "[233, 2, 41, 62, 65, 234, 2]\n",
            "[233, 2, 41, 62, 65, 234, 2, 235]\n",
            "[233, 2, 41, 62, 65, 234, 2, 235]\n",
            "[1, 236]\n",
            "[1, 236, 5]\n",
            "[1, 236, 5, 2]\n",
            "[1, 236, 5, 2, 237]\n",
            "[1, 236, 5, 2, 237, 12]\n",
            "[1, 236, 5, 2, 237, 12, 9]\n",
            "[1, 236, 5, 2, 237, 12, 9, 10]\n",
            "[1, 236, 5, 2, 237, 12, 9, 10]\n",
            "[24, 238]\n",
            "[24, 238, 24]\n",
            "[24, 238, 24, 239]\n",
            "[24, 238, 24, 239, 240]\n",
            "[24, 238, 24, 239, 240, 28]\n",
            "[24, 238, 24, 239, 240, 28, 11]\n",
            "[24, 238, 24, 239, 240, 28, 11, 241]\n",
            "[24, 238, 24, 239, 240, 28, 11, 241]\n",
            "[46, 23]\n",
            "[46, 23, 3]\n",
            "[46, 23, 3, 242]\n",
            "[46, 23, 3, 242, 65]\n",
            "[46, 23, 3, 242, 65, 243]\n",
            "[46, 23, 3, 242, 65, 243, 244]\n",
            "[46, 23, 3, 242, 65, 243, 244, 245]\n",
            "[46, 23, 3, 242, 65, 243, 244, 245]\n",
            "[6, 53]\n",
            "[6, 53, 246]\n",
            "[6, 53, 246, 13]\n",
            "[6, 53, 246, 13, 16]\n",
            "[6, 53, 246, 13, 16, 247]\n",
            "[6, 53, 246, 13, 16, 247]\n",
            "[1, 248]\n",
            "[1, 248, 31]\n",
            "[1, 248, 31, 3]\n",
            "[1, 248, 31, 3, 249]\n",
            "[1, 248, 31, 3, 249, 250]\n",
            "[1, 248, 31, 3, 249, 250]\n",
            "[55, 251]\n",
            "[55, 251, 2]\n",
            "[55, 251, 2, 252]\n",
            "[55, 251, 2, 252, 34]\n",
            "[55, 251, 2, 252, 34, 253]\n",
            "[55, 251, 2, 252, 34, 253, 254]\n",
            "[55, 251, 2, 252, 34, 253, 254, 255]\n",
            "[55, 251, 2, 252, 34, 253, 254, 255]\n",
            "[19, 256]\n",
            "[19, 256, 31]\n",
            "[19, 256, 31, 16]\n",
            "[19, 256, 31, 16, 257]\n",
            "[19, 256, 31, 16, 257, 258]\n",
            "[19, 256, 31, 16, 257, 258, 259]\n",
            "[19, 256, 31, 16, 257, 258, 259, 1]\n",
            "[19, 256, 31, 16, 257, 258, 259, 1, 5]\n",
            "[19, 256, 31, 16, 257, 258, 259, 1, 5]\n",
            "[2, 17]\n",
            "[2, 17, 4]\n",
            "[2, 17, 4, 56]\n",
            "[2, 17, 4, 56, 260]\n",
            "[2, 17, 4, 56, 260, 19]\n",
            "[2, 17, 4, 56, 260, 19, 23]\n",
            "[2, 17, 4, 56, 260, 19, 23, 5]\n",
            "[2, 17, 4, 56, 260, 19, 23, 5, 261]\n",
            "[2, 17, 4, 56, 260, 19, 23, 5, 261]\n",
            "[1, 26]\n",
            "[1, 26, 61]\n",
            "[1, 26, 61, 60]\n",
            "[1, 26, 61, 60, 262]\n",
            "[1, 26, 61, 60, 262, 13]\n",
            "[1, 26, 61, 60, 262, 13, 9]\n",
            "[1, 26, 61, 60, 262, 13, 9, 10]\n",
            "[1, 26, 61, 60, 262, 13, 9, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcDolBJrD5Lm",
        "outputId": "ecd7d8c0-5298-49e5-de8d-ef386d1222ad"
      },
      "source": [
        "input_sequences=[]\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)+1):\n",
        "    sub_seq = token_list[:i+1]\n",
        "    input_sequences.append(sub_seq)\n",
        "print(input_sequences)\n",
        "print('size of training set: {}'.format(len(input_sequences)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4, 2], [4, 2, 66], [4, 2, 66, 8], [4, 2, 66, 8, 67], [4, 2, 66, 8, 67, 68], [4, 2, 66, 8, 67, 68, 69], [4, 2, 66, 8, 67, 68, 69, 70], [4, 2, 66, 8, 67, 68, 69, 70], [71, 40], [71, 40, 20], [71, 40, 20, 21], [71, 40, 20, 21, 72], [71, 40, 20, 21, 72, 3], [71, 40, 20, 21, 72, 3, 73], [71, 40, 20, 21, 72, 3, 73], [16, 74], [16, 74, 75], [16, 74, 75, 1], [16, 74, 75, 1, 76], [16, 74, 75, 1, 76, 33], [16, 74, 75, 1, 76, 33, 3], [16, 74, 75, 1, 76, 33, 3, 77], [16, 74, 75, 1, 76, 33, 3, 77, 22], [16, 74, 75, 1, 76, 33, 3, 77, 22], [41, 33], [41, 33, 3], [41, 33, 3, 78], [41, 33, 3, 78, 1], [41, 33, 3, 78, 1, 79], [41, 33, 3, 78, 1, 79, 80], [41, 33, 3, 78, 1, 79, 80, 8], [41, 33, 3, 78, 1, 79, 80, 8, 81], [41, 33, 3, 78, 1, 79, 80, 8, 81], [21, 82], [21, 82, 3], [21, 82, 3, 83], [21, 82, 3, 83, 84], [21, 82, 3, 83, 84, 7], [21, 82, 3, 83, 84, 7, 42], [21, 82, 3, 83, 84, 7, 42, 1], [21, 82, 3, 83, 84, 7, 42, 1, 43], [21, 82, 3, 83, 84, 7, 42, 1, 43], [85, 86], [85, 86, 87], [85, 86, 87, 33], [85, 86, 87, 33, 44], [85, 86, 87, 33, 44, 88], [85, 86, 87, 33, 44, 88, 13], [85, 86, 87, 33, 44, 88, 13, 2], [85, 86, 87, 33, 44, 88, 13, 2, 45], [85, 86, 87, 33, 44, 88, 13, 2, 45], [1, 89], [1, 89, 90], [1, 89, 90, 91], [1, 89, 90, 91, 92], [1, 89, 90, 91, 92, 93], [1, 89, 90, 91, 92, 93, 94], [1, 89, 90, 91, 92, 93, 94, 95], [1, 89, 90, 91, 92, 93, 94, 95, 96], [1, 89, 90, 91, 92, 93, 94, 95, 96, 97], [1, 89, 90, 91, 92, 93, 94, 95, 96, 97], [8, 2], [8, 2, 98], [8, 2, 98, 1], [8, 2, 98, 1, 2], [8, 2, 98, 1, 2, 99], [8, 2, 98, 1, 2, 99, 8], [8, 2, 98, 1, 2, 99, 8, 9], [8, 2, 98, 1, 2, 99, 8, 9, 10], [8, 2, 98, 1, 2, 99, 8, 9, 10], [46, 13], [46, 13, 100], [46, 13, 100, 101], [46, 13, 100, 101, 23], [46, 13, 100, 101, 23, 102], [46, 13, 100, 101, 23, 102, 103], [46, 13, 100, 101, 23, 102, 103], [7, 5], [7, 5, 2], [7, 5, 2, 47], [7, 5, 2, 47, 17], [7, 5, 2, 47, 17, 1], [7, 5, 2, 47, 17, 1, 24], [7, 5, 2, 47, 17, 1, 24, 6], [7, 5, 2, 47, 17, 1, 24, 6, 104], [7, 5, 2, 47, 17, 1, 24, 6, 104, 105], [7, 5, 2, 47, 17, 1, 24, 6, 104, 105], [1, 48], [1, 48, 4], [1, 48, 4, 3], [1, 48, 4, 3, 106], [1, 48, 4, 3, 106, 107], [1, 48, 4, 3, 106, 107, 42], [1, 48, 4, 3, 106, 107, 42, 1], [1, 48, 4, 3, 106, 107, 42, 1, 43], [1, 48, 4, 3, 106, 107, 42, 1, 43], [11, 49], [11, 49, 25], [11, 49, 25, 50], [11, 49, 25, 50, 18], [11, 49, 25, 50, 18, 108], [11, 49, 25, 50, 18, 108, 25], [11, 49, 25, 50, 18, 108, 25, 3], [11, 49, 25, 50, 18, 108, 25, 3, 109], [11, 49, 25, 50, 18, 108, 25, 3, 109], [110, 111], [110, 111, 26], [110, 111, 26, 47], [110, 111, 26, 47, 112], [110, 111, 26, 47, 112, 113], [110, 111, 26, 47, 112, 113], [14, 51], [14, 51, 52], [14, 51, 52, 3], [14, 51, 52, 3, 114], [14, 51, 52, 3, 114, 7], [14, 51, 52, 3, 114, 7, 13], [14, 51, 52, 3, 114, 7, 13, 115], [14, 51, 52, 3, 114, 7, 13, 115, 27], [14, 51, 52, 3, 114, 7, 13, 115, 27, 3], [14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116], [14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116], [1, 6], [1, 6, 53], [1, 6, 53, 117], [1, 6, 53, 117, 118], [1, 6, 53, 117, 118, 119], [1, 6, 53, 117, 118, 119, 120], [1, 6, 53, 117, 118, 119, 120], [48, 4], [48, 4, 54], [48, 4, 54, 7], [48, 4, 54, 7, 9], [48, 4, 54, 7, 9, 10], [48, 4, 54, 7, 9, 10], [28, 11], [28, 11, 121], [28, 11, 121, 8], [28, 11, 121, 8, 122], [28, 11, 121, 8, 122, 1], [28, 11, 121, 8, 122, 1, 123], [28, 11, 121, 8, 122, 1, 123, 7], [28, 11, 121, 8, 122, 1, 123, 7, 2], [28, 11, 121, 8, 122, 1, 123, 7, 2, 124], [28, 11, 121, 8, 122, 1, 123, 7, 2, 124], [125, 1], [125, 1, 126], [125, 1, 126, 28], [125, 1, 126, 28, 34], [125, 1, 126, 28, 34, 127], [125, 1, 126, 28, 34, 127, 1], [125, 1, 126, 28, 34, 127, 1, 128], [125, 1, 126, 28, 34, 127, 1, 128], [28, 11], [28, 11, 2], [28, 11, 2, 129], [28, 11, 2, 129, 130], [28, 11, 2, 129, 130, 131], [28, 11, 2, 129, 130, 131], [132, 2], [132, 2, 17], [132, 2, 17, 1], [132, 2, 17, 1, 49], [132, 2, 17, 1, 49, 40], [132, 2, 17, 1, 49, 40], [133, 19], [133, 19, 134], [133, 19, 134, 25], [133, 19, 134, 25, 18], [133, 19, 134, 25, 18, 135], [133, 19, 134, 25, 18, 135, 18], [133, 19, 134, 25, 18, 135, 18, 136], [133, 19, 134, 25, 18, 135, 18, 136], [2, 137], [2, 137, 26], [2, 137, 26, 138], [2, 137, 26, 138, 139], [2, 137, 26, 138, 139, 4], [2, 137, 26, 138, 139, 4, 140], [2, 137, 26, 138, 139, 4, 140, 55], [2, 137, 26, 138, 139, 4, 140, 55, 141], [2, 137, 26, 138, 139, 4, 140, 55, 141], [142, 143], [142, 143, 144], [142, 143, 144, 1], [142, 143, 144, 1, 2], [142, 143, 144, 1, 2, 145], [142, 143, 144, 1, 2, 145, 146], [142, 143, 144, 1, 2, 145, 146, 147], [142, 143, 144, 1, 2, 145, 146, 147], [5, 148], [5, 148, 149], [5, 148, 149, 12], [5, 148, 149, 12, 9], [5, 148, 149, 12, 9, 10], [5, 148, 149, 12, 9, 10], [19, 11], [19, 11, 150], [19, 11, 150, 5], [19, 11, 150, 5, 151], [19, 11, 150, 5, 151, 8], [19, 11, 150, 5, 151, 8, 152], [19, 11, 150, 5, 151, 8, 152, 153], [19, 11, 150, 5, 151, 8, 152, 153], [5, 25], [5, 25, 2], [5, 25, 2, 154], [5, 25, 2, 154, 4], [5, 25, 2, 154, 4, 3], [5, 25, 2, 154, 4, 3, 155], [5, 25, 2, 154, 4, 3, 155], [156, 1], [156, 1, 6], [156, 1, 6, 157], [156, 1, 6, 157, 158], [156, 1, 6, 157, 158, 56], [156, 1, 6, 157, 158, 56, 159], [156, 1, 6, 157, 158, 56, 159], [1, 51], [1, 51, 57], [1, 51, 57, 2], [1, 51, 57, 2, 160], [1, 51, 57, 2, 160, 8], [1, 51, 57, 2, 160, 8, 3], [1, 51, 57, 2, 160, 8, 3, 161], [1, 51, 57, 2, 160, 8, 3, 161, 1], [1, 51, 57, 2, 160, 8, 3, 161, 1, 3], [1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162], [1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162], [163, 164], [163, 164, 165], [163, 164, 165, 2], [163, 164, 165, 2, 17], [163, 164, 165, 2, 17, 23], [163, 164, 165, 2, 17, 23, 5], [163, 164, 165, 2, 17, 23, 5, 166], [163, 164, 165, 2, 17, 23, 5, 166, 12], [163, 164, 165, 2, 17, 23, 5, 166, 12, 52], [163, 164, 165, 2, 17, 23, 5, 166, 12, 52], [58, 20], [58, 20, 167], [58, 20, 167, 168], [58, 20, 167, 168, 2], [58, 20, 167, 168, 2, 169], [58, 20, 167, 168, 2, 169, 170], [58, 20, 167, 168, 2, 169, 170, 171], [58, 20, 167, 168, 2, 169, 170, 171], [7, 6], [7, 6, 35], [7, 6, 35, 29], [7, 6, 35, 29, 30], [7, 6, 35, 29, 30, 12], [7, 6, 35, 29, 30, 12, 172], [7, 6, 35, 29, 30, 12, 172, 173], [7, 6, 35, 29, 30, 12, 172, 173], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [36, 37, 38, 7, 9, 10], [29, 39], [29, 39, 30], [29, 39, 30, 6], [29, 39, 30, 6, 35], [29, 39, 30, 6, 35, 31], [29, 39, 30, 6, 35, 31, 4], [29, 39, 30, 6, 35, 31, 4, 59], [29, 39, 30, 6, 35, 31, 4, 59], [29, 39], [29, 39, 30], [29, 39, 30, 13], [29, 39, 30, 13, 174], [29, 39, 30, 13, 174, 175], [29, 39, 30, 13, 174, 175, 12], [29, 39, 30, 13, 174, 175, 12, 5], [29, 39, 30, 13, 174, 175, 12, 5], [29, 39], [29, 39, 30], [29, 39, 30, 6], [29, 39, 30, 6, 35], [29, 39, 30, 6, 35, 31], [29, 39, 30, 6, 35, 31, 4], [29, 39, 30, 6, 35, 31, 4, 59], [29, 39, 30, 6, 35, 31, 4, 59], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [36, 37, 38, 7, 9, 10], [14, 15], [14, 15, 32], [14, 15, 32, 1], [14, 15, 32, 1, 6], [14, 15, 32, 1, 6, 15], [14, 15, 32, 1, 6, 15, 4], [14, 15, 32, 1, 6, 15, 4, 22], [14, 15, 32, 1, 6, 15, 4, 22], [6, 15], [6, 15, 32], [6, 15, 32, 1], [6, 15, 32, 1, 14], [6, 15, 32, 1, 14, 15], [6, 15, 32, 1, 14, 15, 4], [6, 15, 32, 1, 14, 15, 4, 22], [6, 15, 32, 1, 14, 15, 4, 22], [14, 15], [14, 15, 32], [14, 15, 32, 1], [14, 15, 32, 1, 6], [14, 15, 32, 1, 6, 15], [14, 15, 32, 1, 6, 15, 4], [14, 15, 32, 1, 6, 15, 4, 22], [14, 15, 32, 1, 6, 15, 4, 22], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [36, 37, 38, 7, 9, 10], [24, 11], [24, 11, 5], [24, 11, 5, 50], [24, 11, 5, 50, 1], [24, 11, 5, 50, 1, 2], [24, 11, 5, 50, 1, 2, 17], [24, 11, 5, 50, 1, 2, 17, 19], [24, 11, 5, 50, 1, 2, 17, 19, 11], [24, 11, 5, 50, 1, 2, 17, 19, 11, 176], [24, 11, 5, 50, 1, 2, 17, 19, 11, 176], [1, 58], [1, 58, 5], [1, 58, 5, 177], [1, 58, 5, 177, 4], [1, 58, 5, 177, 4, 178], [1, 58, 5, 177, 4, 178, 1], [1, 58, 5, 177, 4, 178, 1, 179], [1, 58, 5, 177, 4, 178, 1, 179], [20, 60], [20, 60, 180], [20, 60, 180, 181], [20, 60, 180, 181, 182], [20, 60, 180, 181, 182, 183], [20, 60, 180, 181, 182, 183, 184], [20, 60, 180, 181, 182, 183, 184], [61, 16], [61, 16, 185], [61, 16, 185, 62], [61, 16, 185, 62, 186], [61, 16, 185, 62, 186, 63], [61, 16, 185, 62, 186, 63, 187], [61, 16, 185, 62, 186, 63, 187, 188], [61, 16, 185, 62, 186, 63, 187, 188], [189, 190], [189, 190, 64], [189, 190, 64, 1], [189, 190, 64, 1, 191], [189, 190, 64, 1, 191, 192], [189, 190, 64, 1, 191, 192, 193], [189, 190, 64, 1, 191, 192, 193], [194, 7], [194, 7, 27], [194, 7, 27, 195], [194, 7, 27, 195, 1], [194, 7, 27, 195, 1, 196], [194, 7, 27, 195, 1, 196, 57], [194, 7, 27, 195, 1, 196, 57, 5], [194, 7, 27, 195, 1, 196, 57, 5], [197, 198], [197, 198, 26], [197, 198, 26, 199], [197, 198, 26, 199, 200], [197, 198, 26, 199, 200, 201], [197, 198, 26, 199, 200, 201, 202], [197, 198, 26, 199, 200, 201, 202], [20, 21], [20, 21, 203], [20, 21, 203, 204], [20, 21, 203, 204, 12], [20, 21, 203, 204, 12, 9], [20, 21, 203, 204, 12, 9, 10], [20, 21, 203, 204, 12, 9, 10], [4, 2], [4, 2, 205], [4, 2, 205, 8], [4, 2, 205, 8, 2], [4, 2, 205, 8, 2, 206], [4, 2, 205, 8, 2, 206, 63], [4, 2, 205, 8, 2, 206, 63, 207], [4, 2, 205, 8, 2, 206, 63, 207, 64], [4, 2, 205, 8, 2, 206, 63, 207, 64], [27, 208], [27, 208, 12], [27, 208, 12, 2], [27, 208, 12, 2, 209], [27, 208, 12, 2, 209, 54], [27, 208, 12, 2, 209, 54, 18], [27, 208, 12, 2, 209, 54, 18, 210], [27, 208, 12, 2, 209, 54, 18, 210, 18], [27, 208, 12, 2, 209, 54, 18, 210, 18, 3], [27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211], [27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211], [212, 8], [212, 8, 2], [212, 8, 2, 213], [212, 8, 2, 213, 214], [212, 8, 2, 213, 214, 14], [212, 8, 2, 213, 214, 14, 34], [212, 8, 2, 213, 214, 14, 34, 215], [212, 8, 2, 213, 214, 14, 34, 215], [14, 216], [14, 216, 3], [14, 216, 3, 217], [14, 216, 3, 217, 218], [14, 216, 3, 217, 218, 219], [14, 216, 3, 217, 218, 219, 220], [14, 216, 3, 217, 218, 219, 220, 6], [14, 216, 3, 217, 218, 219, 220, 6, 221], [14, 216, 3, 217, 218, 219, 220, 6, 221], [27, 222], [27, 222, 223], [27, 222, 223, 224], [27, 222, 223, 224, 225], [27, 222, 223, 224, 225, 226], [27, 222, 223, 224, 225, 226, 1], [27, 222, 223, 224, 225, 226, 1, 227], [27, 222, 223, 224, 225, 226, 1, 227], [44, 21], [44, 21, 228], [44, 21, 228, 16], [44, 21, 228, 16, 229], [44, 21, 228, 16, 229, 230], [44, 21, 228, 16, 229, 230, 231], [44, 21, 228, 16, 229, 230, 231, 32], [44, 21, 228, 16, 229, 230, 231, 32, 232], [44, 21, 228, 16, 229, 230, 231, 32, 232, 2], [44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45], [44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45], [233, 2], [233, 2, 41], [233, 2, 41, 62], [233, 2, 41, 62, 65], [233, 2, 41, 62, 65, 234], [233, 2, 41, 62, 65, 234, 2], [233, 2, 41, 62, 65, 234, 2, 235], [233, 2, 41, 62, 65, 234, 2, 235], [1, 236], [1, 236, 5], [1, 236, 5, 2], [1, 236, 5, 2, 237], [1, 236, 5, 2, 237, 12], [1, 236, 5, 2, 237, 12, 9], [1, 236, 5, 2, 237, 12, 9, 10], [1, 236, 5, 2, 237, 12, 9, 10], [24, 238], [24, 238, 24], [24, 238, 24, 239], [24, 238, 24, 239, 240], [24, 238, 24, 239, 240, 28], [24, 238, 24, 239, 240, 28, 11], [24, 238, 24, 239, 240, 28, 11, 241], [24, 238, 24, 239, 240, 28, 11, 241], [46, 23], [46, 23, 3], [46, 23, 3, 242], [46, 23, 3, 242, 65], [46, 23, 3, 242, 65, 243], [46, 23, 3, 242, 65, 243, 244], [46, 23, 3, 242, 65, 243, 244, 245], [46, 23, 3, 242, 65, 243, 244, 245], [6, 53], [6, 53, 246], [6, 53, 246, 13], [6, 53, 246, 13, 16], [6, 53, 246, 13, 16, 247], [6, 53, 246, 13, 16, 247], [1, 248], [1, 248, 31], [1, 248, 31, 3], [1, 248, 31, 3, 249], [1, 248, 31, 3, 249, 250], [1, 248, 31, 3, 249, 250], [55, 251], [55, 251, 2], [55, 251, 2, 252], [55, 251, 2, 252, 34], [55, 251, 2, 252, 34, 253], [55, 251, 2, 252, 34, 253, 254], [55, 251, 2, 252, 34, 253, 254, 255], [55, 251, 2, 252, 34, 253, 254, 255], [19, 256], [19, 256, 31], [19, 256, 31, 16], [19, 256, 31, 16, 257], [19, 256, 31, 16, 257, 258], [19, 256, 31, 16, 257, 258, 259], [19, 256, 31, 16, 257, 258, 259, 1], [19, 256, 31, 16, 257, 258, 259, 1, 5], [19, 256, 31, 16, 257, 258, 259, 1, 5], [2, 17], [2, 17, 4], [2, 17, 4, 56], [2, 17, 4, 56, 260], [2, 17, 4, 56, 260, 19], [2, 17, 4, 56, 260, 19, 23], [2, 17, 4, 56, 260, 19, 23, 5], [2, 17, 4, 56, 260, 19, 23, 5, 261], [2, 17, 4, 56, 260, 19, 23, 5, 261], [1, 26], [1, 26, 61], [1, 26, 61, 60], [1, 26, 61, 60, 262], [1, 26, 61, 60, 262, 13], [1, 26, 61, 60, 262, 13, 9], [1, 26, 61, 60, 262, 13, 9, 10], [1, 26, 61, 60, 262, 13, 9, 10]]\n",
            "size of training set: 517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2avqaGTFryX"
      },
      "source": [
        "## Find out the longest length of sequence in `input_sequences`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATXAEiT6FKwb",
        "outputId": "12117c0f-28b6-4176-ad51-9e14a23e3494"
      },
      "source": [
        "max_sequences_len = max([len(x) for x in input_sequences])\n",
        "print('max length of the sequences: {}'.format(max_sequences_len))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length of the sequences: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNRDS2gIhwY"
      },
      "source": [
        "## Use `pad_sequences` to pad all the sequences, so they are the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8ZKrQgtGDxu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded = pad_sequences(input_sequences, maxlen=max_sequences_len, padding='pre')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCmDw9R1JUTE"
      },
      "source": [
        "## Convert the padded list to the numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL88VRKgJKSf",
        "outputId": "069be68b-1ff9-4bce-cca8-d6e28b79b56a"
      },
      "source": [
        "import numpy as np\n",
        "padded = np.array(padded)\n",
        "print(padded)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0   4   2]\n",
            " [  0   0   0 ...   4   2  66]\n",
            " [  0   0   0 ...   2  66   8]\n",
            " ...\n",
            " [  0   0   0 ... 262  13   9]\n",
            " [  0   0   0 ...  13   9  10]\n",
            " [  0   0   0 ...  13   9  10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ_f4_SUKgF5"
      },
      "source": [
        "## Create `xs` or predictors and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXS07Z-qLUPD",
        "outputId": "44eb856a-e629-4f83-99f5-7905a042bea7"
      },
      "source": [
        "example = np.array([[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]], np.int32)\n",
        "print('example: \\n{} \\n'.format(example))\n",
        "\n",
        "x = example[:,:-1]\n",
        "print('x: \\n{}\\n'.format(x))\n",
        "\n",
        "y = example[:,-1]\n",
        "print('y: \\n{} \\n'.format(y))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example: \n",
            "[[ 1  2  3  4  5  6]\n",
            " [ 7  8  9 10 11 12]] \n",
            "\n",
            "x: \n",
            "[[ 1  2  3  4  5]\n",
            " [ 7  8  9 10 11]]\n",
            "\n",
            "y: \n",
            "[ 6 12] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAn39KVYJfuH"
      },
      "source": [
        "xs = padded[:,:-1]\n",
        "labels = padded[:,-1]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZBinQOYK3_m",
        "outputId": "36d88502-c75d-4f43-b220-16369009cbdd"
      },
      "source": [
        "print(padded[0])\n",
        "print(xs[0])\n",
        "print(labels[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 4 2]\n",
            "[0 0 0 0 0 0 0 0 0 4]\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SzN8FzrK7dn",
        "outputId": "938a480c-5420-4c3a-be35-ac27b3b4f0ea"
      },
      "source": [
        "print(padded[1])\n",
        "print(xs[1])\n",
        "print(labels[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  4  2 66]\n",
            "[0 0 0 0 0 0 0 0 4 2]\n",
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_wsJeoKLPiV",
        "outputId": "d5d35049-1a55-40f2-b0ee-7e5930337b82"
      },
      "source": [
        "print(padded[2])\n",
        "print(xs[2])\n",
        "print(labels[2])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  4  2 66  8]\n",
            "[ 0  0  0  0  0  0  0  4  2 66]\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7171l_yO3_S"
      },
      "source": [
        "## one-hot encode the labels as this is a classification problem: \n",
        "use the contrast utility to convert a list to a categorical. Simply give the list of labels and the number of classes which is total number of words, and it will create a one-hot encoding of the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwKXBg00MgsZ",
        "outputId": "c69b562c-4036-4ad8-d063-17c6e4748246"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
        "print(ys)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTgGCnxzPIkx",
        "outputId": "820eb842-5254-47c3-b2d3-e75db6c7da57"
      },
      "source": [
        "print('the first sequence: \\n{}\\n'.format(padded[0]))\n",
        "print('xs[0]: \\n{}\\n'.format(xs[0]))\n",
        "print('the label of xs[0]: \\n{}\\n'.format(labels[0]))\n",
        "print('one hot representation of the label: \\n{}\\n'.format(ys))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the first sequence: \n",
            "[0 0 0 0 0 0 0 0 0 4 2]\n",
            "\n",
            "xs[0]: \n",
            "[0 0 0 0 0 0 0 0 0 4]\n",
            "\n",
            "the label of xs[0]: \n",
            "2\n",
            "\n",
            "one hot representation of the label: \n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y--rhVgTUq_t"
      },
      "source": [
        "## Let's look at another example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_fsY6TJQM-n",
        "outputId": "810c1028-0b9e-4b5f-a077-3a5df5908151"
      },
      "source": [
        "print('Example padded sentence: \\n{}\\n'.format(padded[6]))\n",
        "original_sentence = ''\n",
        "for index in padded[6]:\n",
        "  for key, value in word_index.items():\n",
        "    if value==index:\n",
        "      original_sentence+= key + ' '\n",
        "print('Original sentence was: \\n{}\\n'.format(original_sentence))\n",
        "print('xs: \\n{}\\n'.format(xs[6]))\n",
        "print('Label: \\n{}\\n'.format(labels[6]))\n",
        "print('ys: \\n{}\\n'.format(ys[6]))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example padded sentence: \n",
            "[ 0  0  0  4  2 66  8 67 68 69 70]\n",
            "\n",
            "Original sentence was: \n",
            "in the town of athy one jeremy lanigan \n",
            "\n",
            "xs: \n",
            "[ 0  0  0  4  2 66  8 67 68 69]\n",
            "\n",
            "Label: \n",
            "70\n",
            "\n",
            "ys: \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WR-LzwLZ_I3"
      },
      "source": [
        "## Build a LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u98VCS_eU18e",
        "outputId": "ea1cf67a-0fa1-4852-8337-968418325c54"
      },
      "source": [
        "  model = tf.keras.models.Sequential([tf.keras.layers.Embedding(total_words, 64, input_length=max_sequences_len-1),\n",
        "                                      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
        "                                      tf.keras.layers.Dense(total_words, activation='softmax')])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=2)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "17/17 - 3s - loss: 5.5668 - accuracy: 0.0368\n",
            "Epoch 2/500\n",
            "17/17 - 0s - loss: 5.5357 - accuracy: 0.0522\n",
            "Epoch 3/500\n",
            "17/17 - 0s - loss: 5.4483 - accuracy: 0.0445\n",
            "Epoch 4/500\n",
            "17/17 - 0s - loss: 5.2306 - accuracy: 0.0445\n",
            "Epoch 5/500\n",
            "17/17 - 0s - loss: 5.1199 - accuracy: 0.0329\n",
            "Epoch 6/500\n",
            "17/17 - 0s - loss: 5.0641 - accuracy: 0.0445\n",
            "Epoch 7/500\n",
            "17/17 - 0s - loss: 5.0235 - accuracy: 0.0484\n",
            "Epoch 8/500\n",
            "17/17 - 0s - loss: 4.9793 - accuracy: 0.0484\n",
            "Epoch 9/500\n",
            "17/17 - 0s - loss: 4.9303 - accuracy: 0.0716\n",
            "Epoch 10/500\n",
            "17/17 - 0s - loss: 4.8752 - accuracy: 0.0696\n",
            "Epoch 11/500\n",
            "17/17 - 0s - loss: 4.8225 - accuracy: 0.0870\n",
            "Epoch 12/500\n",
            "17/17 - 0s - loss: 4.7571 - accuracy: 0.0967\n",
            "Epoch 13/500\n",
            "17/17 - 0s - loss: 4.6869 - accuracy: 0.0909\n",
            "Epoch 14/500\n",
            "17/17 - 0s - loss: 4.6191 - accuracy: 0.1025\n",
            "Epoch 15/500\n",
            "17/17 - 0s - loss: 4.5484 - accuracy: 0.1122\n",
            "Epoch 16/500\n",
            "17/17 - 0s - loss: 4.4818 - accuracy: 0.1122\n",
            "Epoch 17/500\n",
            "17/17 - 0s - loss: 4.4165 - accuracy: 0.1199\n",
            "Epoch 18/500\n",
            "17/17 - 0s - loss: 4.3634 - accuracy: 0.1296\n",
            "Epoch 19/500\n",
            "17/17 - 0s - loss: 4.2960 - accuracy: 0.1277\n",
            "Epoch 20/500\n",
            "17/17 - 0s - loss: 4.2336 - accuracy: 0.1451\n",
            "Epoch 21/500\n",
            "17/17 - 0s - loss: 4.1703 - accuracy: 0.1470\n",
            "Epoch 22/500\n",
            "17/17 - 0s - loss: 4.0965 - accuracy: 0.1663\n",
            "Epoch 23/500\n",
            "17/17 - 0s - loss: 4.0324 - accuracy: 0.1857\n",
            "Epoch 24/500\n",
            "17/17 - 0s - loss: 3.9707 - accuracy: 0.1992\n",
            "Epoch 25/500\n",
            "17/17 - 0s - loss: 3.9176 - accuracy: 0.2128\n",
            "Epoch 26/500\n",
            "17/17 - 0s - loss: 3.8594 - accuracy: 0.2205\n",
            "Epoch 27/500\n",
            "17/17 - 0s - loss: 3.8017 - accuracy: 0.2302\n",
            "Epoch 28/500\n",
            "17/17 - 0s - loss: 3.7356 - accuracy: 0.2379\n",
            "Epoch 29/500\n",
            "17/17 - 0s - loss: 3.6772 - accuracy: 0.2476\n",
            "Epoch 30/500\n",
            "17/17 - 0s - loss: 3.6199 - accuracy: 0.2592\n",
            "Epoch 31/500\n",
            "17/17 - 0s - loss: 3.5700 - accuracy: 0.2631\n",
            "Epoch 32/500\n",
            "17/17 - 0s - loss: 3.5179 - accuracy: 0.2631\n",
            "Epoch 33/500\n",
            "17/17 - 0s - loss: 3.4902 - accuracy: 0.2650\n",
            "Epoch 34/500\n",
            "17/17 - 0s - loss: 3.4303 - accuracy: 0.2863\n",
            "Epoch 35/500\n",
            "17/17 - 0s - loss: 3.3662 - accuracy: 0.2843\n",
            "Epoch 36/500\n",
            "17/17 - 0s - loss: 3.3134 - accuracy: 0.2805\n",
            "Epoch 37/500\n",
            "17/17 - 0s - loss: 3.2544 - accuracy: 0.2979\n",
            "Epoch 38/500\n",
            "17/17 - 0s - loss: 3.2129 - accuracy: 0.3095\n",
            "Epoch 39/500\n",
            "17/17 - 0s - loss: 3.1676 - accuracy: 0.3250\n",
            "Epoch 40/500\n",
            "17/17 - 0s - loss: 3.1459 - accuracy: 0.3250\n",
            "Epoch 41/500\n",
            "17/17 - 0s - loss: 3.0979 - accuracy: 0.3250\n",
            "Epoch 42/500\n",
            "17/17 - 0s - loss: 3.0471 - accuracy: 0.3462\n",
            "Epoch 43/500\n",
            "17/17 - 0s - loss: 2.9858 - accuracy: 0.3578\n",
            "Epoch 44/500\n",
            "17/17 - 0s - loss: 2.9471 - accuracy: 0.3559\n",
            "Epoch 45/500\n",
            "17/17 - 0s - loss: 2.9069 - accuracy: 0.3772\n",
            "Epoch 46/500\n",
            "17/17 - 0s - loss: 2.8727 - accuracy: 0.3752\n",
            "Epoch 47/500\n",
            "17/17 - 0s - loss: 2.8508 - accuracy: 0.3810\n",
            "Epoch 48/500\n",
            "17/17 - 0s - loss: 2.8110 - accuracy: 0.3791\n",
            "Epoch 49/500\n",
            "17/17 - 0s - loss: 2.7665 - accuracy: 0.3926\n",
            "Epoch 50/500\n",
            "17/17 - 0s - loss: 2.7179 - accuracy: 0.4004\n",
            "Epoch 51/500\n",
            "17/17 - 0s - loss: 2.6855 - accuracy: 0.4101\n",
            "Epoch 52/500\n",
            "17/17 - 0s - loss: 2.6488 - accuracy: 0.4236\n",
            "Epoch 53/500\n",
            "17/17 - 0s - loss: 2.6157 - accuracy: 0.4275\n",
            "Epoch 54/500\n",
            "17/17 - 0s - loss: 2.5872 - accuracy: 0.4391\n",
            "Epoch 55/500\n",
            "17/17 - 0s - loss: 2.5666 - accuracy: 0.4526\n",
            "Epoch 56/500\n",
            "17/17 - 0s - loss: 2.5220 - accuracy: 0.4603\n",
            "Epoch 57/500\n",
            "17/17 - 0s - loss: 2.4827 - accuracy: 0.4584\n",
            "Epoch 58/500\n",
            "17/17 - 0s - loss: 2.4530 - accuracy: 0.4758\n",
            "Epoch 59/500\n",
            "17/17 - 0s - loss: 2.4264 - accuracy: 0.4855\n",
            "Epoch 60/500\n",
            "17/17 - 0s - loss: 2.3911 - accuracy: 0.4932\n",
            "Epoch 61/500\n",
            "17/17 - 0s - loss: 2.3629 - accuracy: 0.4932\n",
            "Epoch 62/500\n",
            "17/17 - 0s - loss: 2.3383 - accuracy: 0.4952\n",
            "Epoch 63/500\n",
            "17/17 - 0s - loss: 2.3033 - accuracy: 0.5126\n",
            "Epoch 64/500\n",
            "17/17 - 0s - loss: 2.2781 - accuracy: 0.5068\n",
            "Epoch 65/500\n",
            "17/17 - 0s - loss: 2.2523 - accuracy: 0.5145\n",
            "Epoch 66/500\n",
            "17/17 - 0s - loss: 2.2145 - accuracy: 0.5280\n",
            "Epoch 67/500\n",
            "17/17 - 0s - loss: 2.1878 - accuracy: 0.5377\n",
            "Epoch 68/500\n",
            "17/17 - 0s - loss: 2.1629 - accuracy: 0.5551\n",
            "Epoch 69/500\n",
            "17/17 - 0s - loss: 2.1320 - accuracy: 0.5648\n",
            "Epoch 70/500\n",
            "17/17 - 0s - loss: 2.1077 - accuracy: 0.5687\n",
            "Epoch 71/500\n",
            "17/17 - 0s - loss: 2.0792 - accuracy: 0.5648\n",
            "Epoch 72/500\n",
            "17/17 - 0s - loss: 2.0666 - accuracy: 0.5822\n",
            "Epoch 73/500\n",
            "17/17 - 0s - loss: 2.0551 - accuracy: 0.5822\n",
            "Epoch 74/500\n",
            "17/17 - 0s - loss: 2.0421 - accuracy: 0.5880\n",
            "Epoch 75/500\n",
            "17/17 - 0s - loss: 2.0353 - accuracy: 0.5919\n",
            "Epoch 76/500\n",
            "17/17 - 0s - loss: 2.0018 - accuracy: 0.6054\n",
            "Epoch 77/500\n",
            "17/17 - 0s - loss: 1.9528 - accuracy: 0.6228\n",
            "Epoch 78/500\n",
            "17/17 - 0s - loss: 1.9309 - accuracy: 0.6035\n",
            "Epoch 79/500\n",
            "17/17 - 0s - loss: 1.9037 - accuracy: 0.6170\n",
            "Epoch 80/500\n",
            "17/17 - 0s - loss: 1.8783 - accuracy: 0.6267\n",
            "Epoch 81/500\n",
            "17/17 - 0s - loss: 1.8790 - accuracy: 0.6344\n",
            "Epoch 82/500\n",
            "17/17 - 0s - loss: 1.8550 - accuracy: 0.6306\n",
            "Epoch 83/500\n",
            "17/17 - 0s - loss: 1.8183 - accuracy: 0.6576\n",
            "Epoch 84/500\n",
            "17/17 - 0s - loss: 1.8011 - accuracy: 0.6480\n",
            "Epoch 85/500\n",
            "17/17 - 0s - loss: 1.7745 - accuracy: 0.6654\n",
            "Epoch 86/500\n",
            "17/17 - 0s - loss: 1.7546 - accuracy: 0.6615\n",
            "Epoch 87/500\n",
            "17/17 - 0s - loss: 1.7353 - accuracy: 0.6750\n",
            "Epoch 88/500\n",
            "17/17 - 0s - loss: 1.7133 - accuracy: 0.6557\n",
            "Epoch 89/500\n",
            "17/17 - 0s - loss: 1.6935 - accuracy: 0.6654\n",
            "Epoch 90/500\n",
            "17/17 - 0s - loss: 1.6741 - accuracy: 0.6712\n",
            "Epoch 91/500\n",
            "17/17 - 0s - loss: 1.6540 - accuracy: 0.6712\n",
            "Epoch 92/500\n",
            "17/17 - 0s - loss: 1.6273 - accuracy: 0.6925\n",
            "Epoch 93/500\n",
            "17/17 - 0s - loss: 1.6043 - accuracy: 0.6963\n",
            "Epoch 94/500\n",
            "17/17 - 0s - loss: 1.5799 - accuracy: 0.7118\n",
            "Epoch 95/500\n",
            "17/17 - 0s - loss: 1.5655 - accuracy: 0.7157\n",
            "Epoch 96/500\n",
            "17/17 - 0s - loss: 1.5507 - accuracy: 0.7137\n",
            "Epoch 97/500\n",
            "17/17 - 0s - loss: 1.5336 - accuracy: 0.7215\n",
            "Epoch 98/500\n",
            "17/17 - 0s - loss: 1.5112 - accuracy: 0.7195\n",
            "Epoch 99/500\n",
            "17/17 - 0s - loss: 1.4974 - accuracy: 0.7215\n",
            "Epoch 100/500\n",
            "17/17 - 0s - loss: 1.4741 - accuracy: 0.7292\n",
            "Epoch 101/500\n",
            "17/17 - 0s - loss: 1.4529 - accuracy: 0.7311\n",
            "Epoch 102/500\n",
            "17/17 - 0s - loss: 1.4328 - accuracy: 0.7505\n",
            "Epoch 103/500\n",
            "17/17 - 0s - loss: 1.4160 - accuracy: 0.7544\n",
            "Epoch 104/500\n",
            "17/17 - 0s - loss: 1.4101 - accuracy: 0.7485\n",
            "Epoch 105/500\n",
            "17/17 - 0s - loss: 1.4151 - accuracy: 0.7389\n",
            "Epoch 106/500\n",
            "17/17 - 0s - loss: 1.3940 - accuracy: 0.7466\n",
            "Epoch 107/500\n",
            "17/17 - 0s - loss: 1.3687 - accuracy: 0.7485\n",
            "Epoch 108/500\n",
            "17/17 - 0s - loss: 1.3461 - accuracy: 0.7544\n",
            "Epoch 109/500\n",
            "17/17 - 0s - loss: 1.3240 - accuracy: 0.7640\n",
            "Epoch 110/500\n",
            "17/17 - 0s - loss: 1.3058 - accuracy: 0.7679\n",
            "Epoch 111/500\n",
            "17/17 - 0s - loss: 1.2880 - accuracy: 0.7621\n",
            "Epoch 112/500\n",
            "17/17 - 0s - loss: 1.2733 - accuracy: 0.7718\n",
            "Epoch 113/500\n",
            "17/17 - 0s - loss: 1.2568 - accuracy: 0.7718\n",
            "Epoch 114/500\n",
            "17/17 - 0s - loss: 1.2418 - accuracy: 0.7795\n",
            "Epoch 115/500\n",
            "17/17 - 0s - loss: 1.2264 - accuracy: 0.7853\n",
            "Epoch 116/500\n",
            "17/17 - 0s - loss: 1.2150 - accuracy: 0.7911\n",
            "Epoch 117/500\n",
            "17/17 - 0s - loss: 1.2194 - accuracy: 0.7795\n",
            "Epoch 118/500\n",
            "17/17 - 0s - loss: 1.2073 - accuracy: 0.7853\n",
            "Epoch 119/500\n",
            "17/17 - 0s - loss: 1.1997 - accuracy: 0.7988\n",
            "Epoch 120/500\n",
            "17/17 - 0s - loss: 1.1761 - accuracy: 0.8008\n",
            "Epoch 121/500\n",
            "17/17 - 0s - loss: 1.1654 - accuracy: 0.8027\n",
            "Epoch 122/500\n",
            "17/17 - 0s - loss: 1.1482 - accuracy: 0.8027\n",
            "Epoch 123/500\n",
            "17/17 - 0s - loss: 1.1295 - accuracy: 0.8124\n",
            "Epoch 124/500\n",
            "17/17 - 0s - loss: 1.1148 - accuracy: 0.8221\n",
            "Epoch 125/500\n",
            "17/17 - 0s - loss: 1.1097 - accuracy: 0.8182\n",
            "Epoch 126/500\n",
            "17/17 - 0s - loss: 1.0904 - accuracy: 0.8221\n",
            "Epoch 127/500\n",
            "17/17 - 0s - loss: 1.0703 - accuracy: 0.8221\n",
            "Epoch 128/500\n",
            "17/17 - 0s - loss: 1.0544 - accuracy: 0.8317\n",
            "Epoch 129/500\n",
            "17/17 - 0s - loss: 1.0455 - accuracy: 0.8259\n",
            "Epoch 130/500\n",
            "17/17 - 0s - loss: 1.0298 - accuracy: 0.8356\n",
            "Epoch 131/500\n",
            "17/17 - 0s - loss: 1.0188 - accuracy: 0.8317\n",
            "Epoch 132/500\n",
            "17/17 - 0s - loss: 1.0083 - accuracy: 0.8414\n",
            "Epoch 133/500\n",
            "17/17 - 0s - loss: 0.9919 - accuracy: 0.8375\n",
            "Epoch 134/500\n",
            "17/17 - 0s - loss: 0.9765 - accuracy: 0.8530\n",
            "Epoch 135/500\n",
            "17/17 - 0s - loss: 0.9661 - accuracy: 0.8491\n",
            "Epoch 136/500\n",
            "17/17 - 0s - loss: 0.9630 - accuracy: 0.8646\n",
            "Epoch 137/500\n",
            "17/17 - 0s - loss: 0.9492 - accuracy: 0.8685\n",
            "Epoch 138/500\n",
            "17/17 - 0s - loss: 0.9363 - accuracy: 0.8627\n",
            "Epoch 139/500\n",
            "17/17 - 0s - loss: 0.9279 - accuracy: 0.8588\n",
            "Epoch 140/500\n",
            "17/17 - 0s - loss: 0.9184 - accuracy: 0.8549\n",
            "Epoch 141/500\n",
            "17/17 - 0s - loss: 0.9018 - accuracy: 0.8607\n",
            "Epoch 142/500\n",
            "17/17 - 0s - loss: 0.8961 - accuracy: 0.8723\n",
            "Epoch 143/500\n",
            "17/17 - 0s - loss: 0.8910 - accuracy: 0.8743\n",
            "Epoch 144/500\n",
            "17/17 - 0s - loss: 0.8792 - accuracy: 0.8743\n",
            "Epoch 145/500\n",
            "17/17 - 0s - loss: 0.8636 - accuracy: 0.8801\n",
            "Epoch 146/500\n",
            "17/17 - 0s - loss: 0.8517 - accuracy: 0.8859\n",
            "Epoch 147/500\n",
            "17/17 - 0s - loss: 0.8389 - accuracy: 0.8781\n",
            "Epoch 148/500\n",
            "17/17 - 0s - loss: 0.8272 - accuracy: 0.8801\n",
            "Epoch 149/500\n",
            "17/17 - 0s - loss: 0.8162 - accuracy: 0.8839\n",
            "Epoch 150/500\n",
            "17/17 - 0s - loss: 0.8076 - accuracy: 0.8781\n",
            "Epoch 151/500\n",
            "17/17 - 0s - loss: 0.7985 - accuracy: 0.8956\n",
            "Epoch 152/500\n",
            "17/17 - 0s - loss: 0.7929 - accuracy: 0.8878\n",
            "Epoch 153/500\n",
            "17/17 - 0s - loss: 0.7804 - accuracy: 0.9052\n",
            "Epoch 154/500\n",
            "17/17 - 0s - loss: 0.7731 - accuracy: 0.8975\n",
            "Epoch 155/500\n",
            "17/17 - 0s - loss: 0.7689 - accuracy: 0.9052\n",
            "Epoch 156/500\n",
            "17/17 - 0s - loss: 0.7659 - accuracy: 0.8936\n",
            "Epoch 157/500\n",
            "17/17 - 0s - loss: 0.7772 - accuracy: 0.8878\n",
            "Epoch 158/500\n",
            "17/17 - 0s - loss: 0.8219 - accuracy: 0.8743\n",
            "Epoch 159/500\n",
            "17/17 - 0s - loss: 0.7755 - accuracy: 0.8956\n",
            "Epoch 160/500\n",
            "17/17 - 0s - loss: 0.7836 - accuracy: 0.8859\n",
            "Epoch 161/500\n",
            "17/17 - 0s - loss: 0.7606 - accuracy: 0.8975\n",
            "Epoch 162/500\n",
            "17/17 - 0s - loss: 0.7503 - accuracy: 0.8975\n",
            "Epoch 163/500\n",
            "17/17 - 0s - loss: 0.7287 - accuracy: 0.8975\n",
            "Epoch 164/500\n",
            "17/17 - 0s - loss: 0.7168 - accuracy: 0.9014\n",
            "Epoch 165/500\n",
            "17/17 - 0s - loss: 0.6953 - accuracy: 0.9033\n",
            "Epoch 166/500\n",
            "17/17 - 0s - loss: 0.6811 - accuracy: 0.9130\n",
            "Epoch 167/500\n",
            "17/17 - 0s - loss: 0.6728 - accuracy: 0.9072\n",
            "Epoch 168/500\n",
            "17/17 - 0s - loss: 0.6659 - accuracy: 0.9149\n",
            "Epoch 169/500\n",
            "17/17 - 0s - loss: 0.6547 - accuracy: 0.9188\n",
            "Epoch 170/500\n",
            "17/17 - 0s - loss: 0.6450 - accuracy: 0.9188\n",
            "Epoch 171/500\n",
            "17/17 - 0s - loss: 0.6366 - accuracy: 0.9149\n",
            "Epoch 172/500\n",
            "17/17 - 0s - loss: 0.6290 - accuracy: 0.9226\n",
            "Epoch 173/500\n",
            "17/17 - 0s - loss: 0.6215 - accuracy: 0.9188\n",
            "Epoch 174/500\n",
            "17/17 - 0s - loss: 0.6164 - accuracy: 0.9168\n",
            "Epoch 175/500\n",
            "17/17 - 0s - loss: 0.6115 - accuracy: 0.9207\n",
            "Epoch 176/500\n",
            "17/17 - 0s - loss: 0.6033 - accuracy: 0.9207\n",
            "Epoch 177/500\n",
            "17/17 - 0s - loss: 0.5905 - accuracy: 0.9265\n",
            "Epoch 178/500\n",
            "17/17 - 0s - loss: 0.5831 - accuracy: 0.9246\n",
            "Epoch 179/500\n",
            "17/17 - 0s - loss: 0.5792 - accuracy: 0.9304\n",
            "Epoch 180/500\n",
            "17/17 - 0s - loss: 0.5713 - accuracy: 0.9342\n",
            "Epoch 181/500\n",
            "17/17 - 0s - loss: 0.5600 - accuracy: 0.9362\n",
            "Epoch 182/500\n",
            "17/17 - 0s - loss: 0.5552 - accuracy: 0.9342\n",
            "Epoch 183/500\n",
            "17/17 - 0s - loss: 0.5488 - accuracy: 0.9362\n",
            "Epoch 184/500\n",
            "17/17 - 0s - loss: 0.5433 - accuracy: 0.9381\n",
            "Epoch 185/500\n",
            "17/17 - 0s - loss: 0.5371 - accuracy: 0.9362\n",
            "Epoch 186/500\n",
            "17/17 - 0s - loss: 0.5352 - accuracy: 0.9439\n",
            "Epoch 187/500\n",
            "17/17 - 0s - loss: 0.5274 - accuracy: 0.9439\n",
            "Epoch 188/500\n",
            "17/17 - 0s - loss: 0.5319 - accuracy: 0.9381\n",
            "Epoch 189/500\n",
            "17/17 - 0s - loss: 0.5294 - accuracy: 0.9400\n",
            "Epoch 190/500\n",
            "17/17 - 0s - loss: 0.5156 - accuracy: 0.9439\n",
            "Epoch 191/500\n",
            "17/17 - 0s - loss: 0.5058 - accuracy: 0.9458\n",
            "Epoch 192/500\n",
            "17/17 - 0s - loss: 0.5059 - accuracy: 0.9400\n",
            "Epoch 193/500\n",
            "17/17 - 0s - loss: 0.5025 - accuracy: 0.9439\n",
            "Epoch 194/500\n",
            "17/17 - 0s - loss: 0.5025 - accuracy: 0.9478\n",
            "Epoch 195/500\n",
            "17/17 - 0s - loss: 0.4932 - accuracy: 0.9458\n",
            "Epoch 196/500\n",
            "17/17 - 0s - loss: 0.4831 - accuracy: 0.9478\n",
            "Epoch 197/500\n",
            "17/17 - 0s - loss: 0.4746 - accuracy: 0.9478\n",
            "Epoch 198/500\n",
            "17/17 - 0s - loss: 0.4716 - accuracy: 0.9439\n",
            "Epoch 199/500\n",
            "17/17 - 0s - loss: 0.4690 - accuracy: 0.9458\n",
            "Epoch 200/500\n",
            "17/17 - 0s - loss: 0.4678 - accuracy: 0.9420\n",
            "Epoch 201/500\n",
            "17/17 - 0s - loss: 0.4662 - accuracy: 0.9439\n",
            "Epoch 202/500\n",
            "17/17 - 0s - loss: 0.4561 - accuracy: 0.9420\n",
            "Epoch 203/500\n",
            "17/17 - 0s - loss: 0.4507 - accuracy: 0.9420\n",
            "Epoch 204/500\n",
            "17/17 - 0s - loss: 0.4431 - accuracy: 0.9478\n",
            "Epoch 205/500\n",
            "17/17 - 0s - loss: 0.4358 - accuracy: 0.9439\n",
            "Epoch 206/500\n",
            "17/17 - 0s - loss: 0.4303 - accuracy: 0.9458\n",
            "Epoch 207/500\n",
            "17/17 - 0s - loss: 0.4270 - accuracy: 0.9458\n",
            "Epoch 208/500\n",
            "17/17 - 0s - loss: 0.4308 - accuracy: 0.9497\n",
            "Epoch 209/500\n",
            "17/17 - 0s - loss: 0.4193 - accuracy: 0.9458\n",
            "Epoch 210/500\n",
            "17/17 - 0s - loss: 0.4154 - accuracy: 0.9420\n",
            "Epoch 211/500\n",
            "17/17 - 0s - loss: 0.4106 - accuracy: 0.9458\n",
            "Epoch 212/500\n",
            "17/17 - 0s - loss: 0.4032 - accuracy: 0.9478\n",
            "Epoch 213/500\n",
            "17/17 - 0s - loss: 0.3984 - accuracy: 0.9497\n",
            "Epoch 214/500\n",
            "17/17 - 0s - loss: 0.3916 - accuracy: 0.9516\n",
            "Epoch 215/500\n",
            "17/17 - 0s - loss: 0.3879 - accuracy: 0.9497\n",
            "Epoch 216/500\n",
            "17/17 - 0s - loss: 0.3864 - accuracy: 0.9497\n",
            "Epoch 217/500\n",
            "17/17 - 0s - loss: 0.3825 - accuracy: 0.9458\n",
            "Epoch 218/500\n",
            "17/17 - 0s - loss: 0.3768 - accuracy: 0.9516\n",
            "Epoch 219/500\n",
            "17/17 - 0s - loss: 0.3709 - accuracy: 0.9516\n",
            "Epoch 220/500\n",
            "17/17 - 0s - loss: 0.3663 - accuracy: 0.9516\n",
            "Epoch 221/500\n",
            "17/17 - 0s - loss: 0.3626 - accuracy: 0.9497\n",
            "Epoch 222/500\n",
            "17/17 - 0s - loss: 0.3604 - accuracy: 0.9516\n",
            "Epoch 223/500\n",
            "17/17 - 0s - loss: 0.3561 - accuracy: 0.9516\n",
            "Epoch 224/500\n",
            "17/17 - 0s - loss: 0.3525 - accuracy: 0.9536\n",
            "Epoch 225/500\n",
            "17/17 - 0s - loss: 0.3507 - accuracy: 0.9536\n",
            "Epoch 226/500\n",
            "17/17 - 0s - loss: 0.3504 - accuracy: 0.9516\n",
            "Epoch 227/500\n",
            "17/17 - 0s - loss: 0.3451 - accuracy: 0.9536\n",
            "Epoch 228/500\n",
            "17/17 - 0s - loss: 0.3438 - accuracy: 0.9536\n",
            "Epoch 229/500\n",
            "17/17 - 0s - loss: 0.3424 - accuracy: 0.9536\n",
            "Epoch 230/500\n",
            "17/17 - 0s - loss: 0.3416 - accuracy: 0.9536\n",
            "Epoch 231/500\n",
            "17/17 - 0s - loss: 0.3405 - accuracy: 0.9536\n",
            "Epoch 232/500\n",
            "17/17 - 0s - loss: 0.3337 - accuracy: 0.9516\n",
            "Epoch 233/500\n",
            "17/17 - 0s - loss: 0.3337 - accuracy: 0.9516\n",
            "Epoch 234/500\n",
            "17/17 - 0s - loss: 0.3269 - accuracy: 0.9497\n",
            "Epoch 235/500\n",
            "17/17 - 0s - loss: 0.3316 - accuracy: 0.9536\n",
            "Epoch 236/500\n",
            "17/17 - 0s - loss: 0.3194 - accuracy: 0.9516\n",
            "Epoch 237/500\n",
            "17/17 - 0s - loss: 0.3149 - accuracy: 0.9516\n",
            "Epoch 238/500\n",
            "17/17 - 0s - loss: 0.3137 - accuracy: 0.9516\n",
            "Epoch 239/500\n",
            "17/17 - 0s - loss: 0.3076 - accuracy: 0.9536\n",
            "Epoch 240/500\n",
            "17/17 - 0s - loss: 0.3027 - accuracy: 0.9536\n",
            "Epoch 241/500\n",
            "17/17 - 0s - loss: 0.3000 - accuracy: 0.9516\n",
            "Epoch 242/500\n",
            "17/17 - 0s - loss: 0.2976 - accuracy: 0.9555\n",
            "Epoch 243/500\n",
            "17/17 - 0s - loss: 0.2963 - accuracy: 0.9516\n",
            "Epoch 244/500\n",
            "17/17 - 0s - loss: 0.2929 - accuracy: 0.9574\n",
            "Epoch 245/500\n",
            "17/17 - 0s - loss: 0.2904 - accuracy: 0.9536\n",
            "Epoch 246/500\n",
            "17/17 - 0s - loss: 0.2866 - accuracy: 0.9497\n",
            "Epoch 247/500\n",
            "17/17 - 0s - loss: 0.2845 - accuracy: 0.9594\n",
            "Epoch 248/500\n",
            "17/17 - 0s - loss: 0.2838 - accuracy: 0.9555\n",
            "Epoch 249/500\n",
            "17/17 - 0s - loss: 0.2812 - accuracy: 0.9574\n",
            "Epoch 250/500\n",
            "17/17 - 0s - loss: 0.2769 - accuracy: 0.9555\n",
            "Epoch 251/500\n",
            "17/17 - 0s - loss: 0.2741 - accuracy: 0.9594\n",
            "Epoch 252/500\n",
            "17/17 - 0s - loss: 0.2713 - accuracy: 0.9555\n",
            "Epoch 253/500\n",
            "17/17 - 0s - loss: 0.2688 - accuracy: 0.9497\n",
            "Epoch 254/500\n",
            "17/17 - 0s - loss: 0.2707 - accuracy: 0.9497\n",
            "Epoch 255/500\n",
            "17/17 - 0s - loss: 0.2714 - accuracy: 0.9478\n",
            "Epoch 256/500\n",
            "17/17 - 0s - loss: 0.2645 - accuracy: 0.9574\n",
            "Epoch 257/500\n",
            "17/17 - 0s - loss: 0.2608 - accuracy: 0.9516\n",
            "Epoch 258/500\n",
            "17/17 - 0s - loss: 0.2595 - accuracy: 0.9574\n",
            "Epoch 259/500\n",
            "17/17 - 0s - loss: 0.2567 - accuracy: 0.9574\n",
            "Epoch 260/500\n",
            "17/17 - 0s - loss: 0.2535 - accuracy: 0.9536\n",
            "Epoch 261/500\n",
            "17/17 - 0s - loss: 0.2519 - accuracy: 0.9574\n",
            "Epoch 262/500\n",
            "17/17 - 0s - loss: 0.2489 - accuracy: 0.9536\n",
            "Epoch 263/500\n",
            "17/17 - 0s - loss: 0.2481 - accuracy: 0.9516\n",
            "Epoch 264/500\n",
            "17/17 - 0s - loss: 0.2472 - accuracy: 0.9574\n",
            "Epoch 265/500\n",
            "17/17 - 0s - loss: 0.2450 - accuracy: 0.9536\n",
            "Epoch 266/500\n",
            "17/17 - 0s - loss: 0.2429 - accuracy: 0.9536\n",
            "Epoch 267/500\n",
            "17/17 - 0s - loss: 0.2406 - accuracy: 0.9555\n",
            "Epoch 268/500\n",
            "17/17 - 0s - loss: 0.2394 - accuracy: 0.9555\n",
            "Epoch 269/500\n",
            "17/17 - 0s - loss: 0.2386 - accuracy: 0.9516\n",
            "Epoch 270/500\n",
            "17/17 - 0s - loss: 0.2367 - accuracy: 0.9555\n",
            "Epoch 271/500\n",
            "17/17 - 0s - loss: 0.2329 - accuracy: 0.9555\n",
            "Epoch 272/500\n",
            "17/17 - 0s - loss: 0.2331 - accuracy: 0.9555\n",
            "Epoch 273/500\n",
            "17/17 - 0s - loss: 0.2323 - accuracy: 0.9574\n",
            "Epoch 274/500\n",
            "17/17 - 0s - loss: 0.2287 - accuracy: 0.9574\n",
            "Epoch 275/500\n",
            "17/17 - 0s - loss: 0.2254 - accuracy: 0.9555\n",
            "Epoch 276/500\n",
            "17/17 - 0s - loss: 0.2240 - accuracy: 0.9555\n",
            "Epoch 277/500\n",
            "17/17 - 0s - loss: 0.2233 - accuracy: 0.9497\n",
            "Epoch 278/500\n",
            "17/17 - 0s - loss: 0.2223 - accuracy: 0.9555\n",
            "Epoch 279/500\n",
            "17/17 - 0s - loss: 0.2205 - accuracy: 0.9516\n",
            "Epoch 280/500\n",
            "17/17 - 0s - loss: 0.2173 - accuracy: 0.9555\n",
            "Epoch 281/500\n",
            "17/17 - 0s - loss: 0.2192 - accuracy: 0.9478\n",
            "Epoch 282/500\n",
            "17/17 - 0s - loss: 0.2157 - accuracy: 0.9536\n",
            "Epoch 283/500\n",
            "17/17 - 0s - loss: 0.2138 - accuracy: 0.9536\n",
            "Epoch 284/500\n",
            "17/17 - 0s - loss: 0.2153 - accuracy: 0.9516\n",
            "Epoch 285/500\n",
            "17/17 - 0s - loss: 0.2122 - accuracy: 0.9555\n",
            "Epoch 286/500\n",
            "17/17 - 0s - loss: 0.2089 - accuracy: 0.9516\n",
            "Epoch 287/500\n",
            "17/17 - 0s - loss: 0.2372 - accuracy: 0.9536\n",
            "Epoch 288/500\n",
            "17/17 - 0s - loss: 0.2541 - accuracy: 0.9516\n",
            "Epoch 289/500\n",
            "17/17 - 0s - loss: 0.2300 - accuracy: 0.9458\n",
            "Epoch 290/500\n",
            "17/17 - 0s - loss: 0.2325 - accuracy: 0.9497\n",
            "Epoch 291/500\n",
            "17/17 - 0s - loss: 0.2409 - accuracy: 0.9478\n",
            "Epoch 292/500\n",
            "17/17 - 0s - loss: 0.2403 - accuracy: 0.9497\n",
            "Epoch 293/500\n",
            "17/17 - 0s - loss: 0.2813 - accuracy: 0.9381\n",
            "Epoch 294/500\n",
            "17/17 - 0s - loss: 0.3270 - accuracy: 0.9149\n",
            "Epoch 295/500\n",
            "17/17 - 0s - loss: 0.2925 - accuracy: 0.9458\n",
            "Epoch 296/500\n",
            "17/17 - 0s - loss: 0.2980 - accuracy: 0.9458\n",
            "Epoch 297/500\n",
            "17/17 - 0s - loss: 0.2672 - accuracy: 0.9420\n",
            "Epoch 298/500\n",
            "17/17 - 0s - loss: 0.2478 - accuracy: 0.9478\n",
            "Epoch 299/500\n",
            "17/17 - 0s - loss: 0.2322 - accuracy: 0.9536\n",
            "Epoch 300/500\n",
            "17/17 - 0s - loss: 0.2151 - accuracy: 0.9555\n",
            "Epoch 301/500\n",
            "17/17 - 0s - loss: 0.2071 - accuracy: 0.9574\n",
            "Epoch 302/500\n",
            "17/17 - 0s - loss: 0.2036 - accuracy: 0.9516\n",
            "Epoch 303/500\n",
            "17/17 - 0s - loss: 0.1985 - accuracy: 0.9555\n",
            "Epoch 304/500\n",
            "17/17 - 0s - loss: 0.1954 - accuracy: 0.9536\n",
            "Epoch 305/500\n",
            "17/17 - 0s - loss: 0.1906 - accuracy: 0.9574\n",
            "Epoch 306/500\n",
            "17/17 - 0s - loss: 0.1884 - accuracy: 0.9536\n",
            "Epoch 307/500\n",
            "17/17 - 0s - loss: 0.1864 - accuracy: 0.9594\n",
            "Epoch 308/500\n",
            "17/17 - 0s - loss: 0.1850 - accuracy: 0.9516\n",
            "Epoch 309/500\n",
            "17/17 - 0s - loss: 0.1837 - accuracy: 0.9516\n",
            "Epoch 310/500\n",
            "17/17 - 0s - loss: 0.1822 - accuracy: 0.9574\n",
            "Epoch 311/500\n",
            "17/17 - 0s - loss: 0.1805 - accuracy: 0.9594\n",
            "Epoch 312/500\n",
            "17/17 - 0s - loss: 0.1809 - accuracy: 0.9574\n",
            "Epoch 313/500\n",
            "17/17 - 0s - loss: 0.1782 - accuracy: 0.9574\n",
            "Epoch 314/500\n",
            "17/17 - 0s - loss: 0.1769 - accuracy: 0.9555\n",
            "Epoch 315/500\n",
            "17/17 - 0s - loss: 0.1766 - accuracy: 0.9536\n",
            "Epoch 316/500\n",
            "17/17 - 0s - loss: 0.1748 - accuracy: 0.9574\n",
            "Epoch 317/500\n",
            "17/17 - 0s - loss: 0.1730 - accuracy: 0.9574\n",
            "Epoch 318/500\n",
            "17/17 - 0s - loss: 0.1719 - accuracy: 0.9574\n",
            "Epoch 319/500\n",
            "17/17 - 0s - loss: 0.1709 - accuracy: 0.9536\n",
            "Epoch 320/500\n",
            "17/17 - 0s - loss: 0.1702 - accuracy: 0.9536\n",
            "Epoch 321/500\n",
            "17/17 - 0s - loss: 0.1688 - accuracy: 0.9555\n",
            "Epoch 322/500\n",
            "17/17 - 0s - loss: 0.1684 - accuracy: 0.9536\n",
            "Epoch 323/500\n",
            "17/17 - 0s - loss: 0.1686 - accuracy: 0.9555\n",
            "Epoch 324/500\n",
            "17/17 - 0s - loss: 0.1667 - accuracy: 0.9555\n",
            "Epoch 325/500\n",
            "17/17 - 0s - loss: 0.1658 - accuracy: 0.9536\n",
            "Epoch 326/500\n",
            "17/17 - 0s - loss: 0.1638 - accuracy: 0.9497\n",
            "Epoch 327/500\n",
            "17/17 - 0s - loss: 0.1634 - accuracy: 0.9516\n",
            "Epoch 328/500\n",
            "17/17 - 0s - loss: 0.1631 - accuracy: 0.9536\n",
            "Epoch 329/500\n",
            "17/17 - 0s - loss: 0.1613 - accuracy: 0.9574\n",
            "Epoch 330/500\n",
            "17/17 - 0s - loss: 0.1618 - accuracy: 0.9555\n",
            "Epoch 331/500\n",
            "17/17 - 0s - loss: 0.1597 - accuracy: 0.9516\n",
            "Epoch 332/500\n",
            "17/17 - 0s - loss: 0.1586 - accuracy: 0.9555\n",
            "Epoch 333/500\n",
            "17/17 - 0s - loss: 0.1576 - accuracy: 0.9555\n",
            "Epoch 334/500\n",
            "17/17 - 0s - loss: 0.1567 - accuracy: 0.9574\n",
            "Epoch 335/500\n",
            "17/17 - 0s - loss: 0.1558 - accuracy: 0.9536\n",
            "Epoch 336/500\n",
            "17/17 - 0s - loss: 0.1554 - accuracy: 0.9497\n",
            "Epoch 337/500\n",
            "17/17 - 0s - loss: 0.1552 - accuracy: 0.9574\n",
            "Epoch 338/500\n",
            "17/17 - 0s - loss: 0.1542 - accuracy: 0.9574\n",
            "Epoch 339/500\n",
            "17/17 - 0s - loss: 0.1548 - accuracy: 0.9574\n",
            "Epoch 340/500\n",
            "17/17 - 0s - loss: 0.1531 - accuracy: 0.9555\n",
            "Epoch 341/500\n",
            "17/17 - 0s - loss: 0.1538 - accuracy: 0.9536\n",
            "Epoch 342/500\n",
            "17/17 - 0s - loss: 0.1531 - accuracy: 0.9555\n",
            "Epoch 343/500\n",
            "17/17 - 0s - loss: 0.1507 - accuracy: 0.9574\n",
            "Epoch 344/500\n",
            "17/17 - 0s - loss: 0.1530 - accuracy: 0.9574\n",
            "Epoch 345/500\n",
            "17/17 - 0s - loss: 0.1499 - accuracy: 0.9555\n",
            "Epoch 346/500\n",
            "17/17 - 0s - loss: 0.1477 - accuracy: 0.9536\n",
            "Epoch 347/500\n",
            "17/17 - 0s - loss: 0.1485 - accuracy: 0.9516\n",
            "Epoch 348/500\n",
            "17/17 - 0s - loss: 0.1470 - accuracy: 0.9555\n",
            "Epoch 349/500\n",
            "17/17 - 0s - loss: 0.1462 - accuracy: 0.9536\n",
            "Epoch 350/500\n",
            "17/17 - 0s - loss: 0.1454 - accuracy: 0.9555\n",
            "Epoch 351/500\n",
            "17/17 - 0s - loss: 0.1453 - accuracy: 0.9555\n",
            "Epoch 352/500\n",
            "17/17 - 0s - loss: 0.1437 - accuracy: 0.9536\n",
            "Epoch 353/500\n",
            "17/17 - 0s - loss: 0.1430 - accuracy: 0.9574\n",
            "Epoch 354/500\n",
            "17/17 - 0s - loss: 0.1442 - accuracy: 0.9574\n",
            "Epoch 355/500\n",
            "17/17 - 0s - loss: 0.1443 - accuracy: 0.9574\n",
            "Epoch 356/500\n",
            "17/17 - 0s - loss: 0.1431 - accuracy: 0.9536\n",
            "Epoch 357/500\n",
            "17/17 - 0s - loss: 0.1421 - accuracy: 0.9516\n",
            "Epoch 358/500\n",
            "17/17 - 0s - loss: 0.2573 - accuracy: 0.9226\n",
            "Epoch 359/500\n",
            "17/17 - 0s - loss: 0.2021 - accuracy: 0.9458\n",
            "Epoch 360/500\n",
            "17/17 - 0s - loss: 0.1963 - accuracy: 0.9439\n",
            "Epoch 361/500\n",
            "17/17 - 0s - loss: 0.2099 - accuracy: 0.9458\n",
            "Epoch 362/500\n",
            "17/17 - 0s - loss: 0.1878 - accuracy: 0.9478\n",
            "Epoch 363/500\n",
            "17/17 - 0s - loss: 0.1715 - accuracy: 0.9555\n",
            "Epoch 364/500\n",
            "17/17 - 0s - loss: 0.1725 - accuracy: 0.9536\n",
            "Epoch 365/500\n",
            "17/17 - 0s - loss: 0.1569 - accuracy: 0.9516\n",
            "Epoch 366/500\n",
            "17/17 - 0s - loss: 0.1489 - accuracy: 0.9555\n",
            "Epoch 367/500\n",
            "17/17 - 0s - loss: 0.1453 - accuracy: 0.9536\n",
            "Epoch 368/500\n",
            "17/17 - 0s - loss: 0.1449 - accuracy: 0.9594\n",
            "Epoch 369/500\n",
            "17/17 - 0s - loss: 0.1428 - accuracy: 0.9497\n",
            "Epoch 370/500\n",
            "17/17 - 0s - loss: 0.1397 - accuracy: 0.9516\n",
            "Epoch 371/500\n",
            "17/17 - 0s - loss: 0.1387 - accuracy: 0.9516\n",
            "Epoch 372/500\n",
            "17/17 - 0s - loss: 0.1367 - accuracy: 0.9497\n",
            "Epoch 373/500\n",
            "17/17 - 0s - loss: 0.1356 - accuracy: 0.9536\n",
            "Epoch 374/500\n",
            "17/17 - 0s - loss: 0.1348 - accuracy: 0.9555\n",
            "Epoch 375/500\n",
            "17/17 - 0s - loss: 0.1339 - accuracy: 0.9536\n",
            "Epoch 376/500\n",
            "17/17 - 0s - loss: 0.1332 - accuracy: 0.9536\n",
            "Epoch 377/500\n",
            "17/17 - 0s - loss: 0.1321 - accuracy: 0.9536\n",
            "Epoch 378/500\n",
            "17/17 - 0s - loss: 0.1316 - accuracy: 0.9574\n",
            "Epoch 379/500\n",
            "17/17 - 0s - loss: 0.1303 - accuracy: 0.9536\n",
            "Epoch 380/500\n",
            "17/17 - 0s - loss: 0.1300 - accuracy: 0.9516\n",
            "Epoch 381/500\n",
            "17/17 - 0s - loss: 0.1295 - accuracy: 0.9536\n",
            "Epoch 382/500\n",
            "17/17 - 0s - loss: 0.1308 - accuracy: 0.9536\n",
            "Epoch 383/500\n",
            "17/17 - 0s - loss: 0.1308 - accuracy: 0.9555\n",
            "Epoch 384/500\n",
            "17/17 - 0s - loss: 0.1283 - accuracy: 0.9574\n",
            "Epoch 385/500\n",
            "17/17 - 0s - loss: 0.1279 - accuracy: 0.9574\n",
            "Epoch 386/500\n",
            "17/17 - 0s - loss: 0.1272 - accuracy: 0.9574\n",
            "Epoch 387/500\n",
            "17/17 - 0s - loss: 0.1265 - accuracy: 0.9536\n",
            "Epoch 388/500\n",
            "17/17 - 0s - loss: 0.1277 - accuracy: 0.9536\n",
            "Epoch 389/500\n",
            "17/17 - 0s - loss: 0.1269 - accuracy: 0.9536\n",
            "Epoch 390/500\n",
            "17/17 - 0s - loss: 0.1256 - accuracy: 0.9516\n",
            "Epoch 391/500\n",
            "17/17 - 0s - loss: 0.1246 - accuracy: 0.9555\n",
            "Epoch 392/500\n",
            "17/17 - 0s - loss: 0.1236 - accuracy: 0.9536\n",
            "Epoch 393/500\n",
            "17/17 - 0s - loss: 0.1232 - accuracy: 0.9536\n",
            "Epoch 394/500\n",
            "17/17 - 0s - loss: 0.1227 - accuracy: 0.9574\n",
            "Epoch 395/500\n",
            "17/17 - 0s - loss: 0.1227 - accuracy: 0.9555\n",
            "Epoch 396/500\n",
            "17/17 - 0s - loss: 0.1218 - accuracy: 0.9536\n",
            "Epoch 397/500\n",
            "17/17 - 0s - loss: 0.1213 - accuracy: 0.9574\n",
            "Epoch 398/500\n",
            "17/17 - 0s - loss: 0.1214 - accuracy: 0.9516\n",
            "Epoch 399/500\n",
            "17/17 - 0s - loss: 0.1212 - accuracy: 0.9536\n",
            "Epoch 400/500\n",
            "17/17 - 0s - loss: 0.1208 - accuracy: 0.9516\n",
            "Epoch 401/500\n",
            "17/17 - 0s - loss: 0.1202 - accuracy: 0.9497\n",
            "Epoch 402/500\n",
            "17/17 - 0s - loss: 0.1198 - accuracy: 0.9497\n",
            "Epoch 403/500\n",
            "17/17 - 0s - loss: 0.1193 - accuracy: 0.9536\n",
            "Epoch 404/500\n",
            "17/17 - 0s - loss: 0.1189 - accuracy: 0.9536\n",
            "Epoch 405/500\n",
            "17/17 - 0s - loss: 0.1179 - accuracy: 0.9555\n",
            "Epoch 406/500\n",
            "17/17 - 0s - loss: 0.1185 - accuracy: 0.9478\n",
            "Epoch 407/500\n",
            "17/17 - 0s - loss: 0.1184 - accuracy: 0.9497\n",
            "Epoch 408/500\n",
            "17/17 - 0s - loss: 0.1173 - accuracy: 0.9555\n",
            "Epoch 409/500\n",
            "17/17 - 0s - loss: 0.1172 - accuracy: 0.9574\n",
            "Epoch 410/500\n",
            "17/17 - 0s - loss: 0.1169 - accuracy: 0.9536\n",
            "Epoch 411/500\n",
            "17/17 - 0s - loss: 0.1169 - accuracy: 0.9536\n",
            "Epoch 412/500\n",
            "17/17 - 0s - loss: 0.1164 - accuracy: 0.9536\n",
            "Epoch 413/500\n",
            "17/17 - 0s - loss: 0.1163 - accuracy: 0.9536\n",
            "Epoch 414/500\n",
            "17/17 - 0s - loss: 0.1162 - accuracy: 0.9516\n",
            "Epoch 415/500\n",
            "17/17 - 0s - loss: 0.1156 - accuracy: 0.9555\n",
            "Epoch 416/500\n",
            "17/17 - 0s - loss: 0.1144 - accuracy: 0.9536\n",
            "Epoch 417/500\n",
            "17/17 - 0s - loss: 0.1143 - accuracy: 0.9516\n",
            "Epoch 418/500\n",
            "17/17 - 0s - loss: 0.1147 - accuracy: 0.9536\n",
            "Epoch 419/500\n",
            "17/17 - 0s - loss: 0.1149 - accuracy: 0.9594\n",
            "Epoch 420/500\n",
            "17/17 - 0s - loss: 0.1215 - accuracy: 0.9497\n",
            "Epoch 421/500\n",
            "17/17 - 0s - loss: 0.1287 - accuracy: 0.9497\n",
            "Epoch 422/500\n",
            "17/17 - 0s - loss: 0.1404 - accuracy: 0.9536\n",
            "Epoch 423/500\n",
            "17/17 - 0s - loss: 0.1387 - accuracy: 0.9478\n",
            "Epoch 424/500\n",
            "17/17 - 0s - loss: 0.1279 - accuracy: 0.9497\n",
            "Epoch 425/500\n",
            "17/17 - 0s - loss: 0.1254 - accuracy: 0.9516\n",
            "Epoch 426/500\n",
            "17/17 - 0s - loss: 0.1199 - accuracy: 0.9574\n",
            "Epoch 427/500\n",
            "17/17 - 0s - loss: 0.1170 - accuracy: 0.9516\n",
            "Epoch 428/500\n",
            "17/17 - 0s - loss: 0.1151 - accuracy: 0.9536\n",
            "Epoch 429/500\n",
            "17/17 - 0s - loss: 0.1141 - accuracy: 0.9516\n",
            "Epoch 430/500\n",
            "17/17 - 0s - loss: 0.1132 - accuracy: 0.9516\n",
            "Epoch 431/500\n",
            "17/17 - 0s - loss: 0.1129 - accuracy: 0.9497\n",
            "Epoch 432/500\n",
            "17/17 - 0s - loss: 0.1119 - accuracy: 0.9516\n",
            "Epoch 433/500\n",
            "17/17 - 0s - loss: 0.1116 - accuracy: 0.9555\n",
            "Epoch 434/500\n",
            "17/17 - 0s - loss: 0.1112 - accuracy: 0.9555\n",
            "Epoch 435/500\n",
            "17/17 - 0s - loss: 0.1117 - accuracy: 0.9536\n",
            "Epoch 436/500\n",
            "17/17 - 0s - loss: 0.1108 - accuracy: 0.9516\n",
            "Epoch 437/500\n",
            "17/17 - 0s - loss: 0.1105 - accuracy: 0.9555\n",
            "Epoch 438/500\n",
            "17/17 - 0s - loss: 0.1103 - accuracy: 0.9555\n",
            "Epoch 439/500\n",
            "17/17 - 0s - loss: 0.1086 - accuracy: 0.9536\n",
            "Epoch 440/500\n",
            "17/17 - 0s - loss: 0.1084 - accuracy: 0.9497\n",
            "Epoch 441/500\n",
            "17/17 - 0s - loss: 0.1082 - accuracy: 0.9536\n",
            "Epoch 442/500\n",
            "17/17 - 0s - loss: 0.1084 - accuracy: 0.9536\n",
            "Epoch 443/500\n",
            "17/17 - 0s - loss: 0.1079 - accuracy: 0.9516\n",
            "Epoch 444/500\n",
            "17/17 - 0s - loss: 0.1072 - accuracy: 0.9536\n",
            "Epoch 445/500\n",
            "17/17 - 0s - loss: 0.1070 - accuracy: 0.9536\n",
            "Epoch 446/500\n",
            "17/17 - 0s - loss: 0.1067 - accuracy: 0.9478\n",
            "Epoch 447/500\n",
            "17/17 - 0s - loss: 0.1075 - accuracy: 0.9458\n",
            "Epoch 448/500\n",
            "17/17 - 0s - loss: 0.1068 - accuracy: 0.9497\n",
            "Epoch 449/500\n",
            "17/17 - 0s - loss: 0.1098 - accuracy: 0.9516\n",
            "Epoch 450/500\n",
            "17/17 - 0s - loss: 0.1073 - accuracy: 0.9574\n",
            "Epoch 451/500\n",
            "17/17 - 0s - loss: 0.1067 - accuracy: 0.9478\n",
            "Epoch 452/500\n",
            "17/17 - 0s - loss: 0.1057 - accuracy: 0.9555\n",
            "Epoch 453/500\n",
            "17/17 - 0s - loss: 0.1053 - accuracy: 0.9555\n",
            "Epoch 454/500\n",
            "17/17 - 0s - loss: 0.1049 - accuracy: 0.9516\n",
            "Epoch 455/500\n",
            "17/17 - 0s - loss: 0.1053 - accuracy: 0.9497\n",
            "Epoch 456/500\n",
            "17/17 - 0s - loss: 0.1039 - accuracy: 0.9516\n",
            "Epoch 457/500\n",
            "17/17 - 0s - loss: 0.1039 - accuracy: 0.9497\n",
            "Epoch 458/500\n",
            "17/17 - 0s - loss: 0.1042 - accuracy: 0.9536\n",
            "Epoch 459/500\n",
            "17/17 - 0s - loss: 0.1043 - accuracy: 0.9536\n",
            "Epoch 460/500\n",
            "17/17 - 0s - loss: 0.1057 - accuracy: 0.9536\n",
            "Epoch 461/500\n",
            "17/17 - 0s - loss: 0.1051 - accuracy: 0.9555\n",
            "Epoch 462/500\n",
            "17/17 - 0s - loss: 0.1052 - accuracy: 0.9555\n",
            "Epoch 463/500\n",
            "17/17 - 0s - loss: 0.1047 - accuracy: 0.9574\n",
            "Epoch 464/500\n",
            "17/17 - 0s - loss: 0.1038 - accuracy: 0.9536\n",
            "Epoch 465/500\n",
            "17/17 - 0s - loss: 0.1028 - accuracy: 0.9536\n",
            "Epoch 466/500\n",
            "17/17 - 0s - loss: 0.1023 - accuracy: 0.9536\n",
            "Epoch 467/500\n",
            "17/17 - 0s - loss: 0.1034 - accuracy: 0.9555\n",
            "Epoch 468/500\n",
            "17/17 - 0s - loss: 0.1023 - accuracy: 0.9536\n",
            "Epoch 469/500\n",
            "17/17 - 0s - loss: 0.1018 - accuracy: 0.9574\n",
            "Epoch 470/500\n",
            "17/17 - 0s - loss: 0.1011 - accuracy: 0.9574\n",
            "Epoch 471/500\n",
            "17/17 - 0s - loss: 0.1012 - accuracy: 0.9536\n",
            "Epoch 472/500\n",
            "17/17 - 0s - loss: 0.1006 - accuracy: 0.9497\n",
            "Epoch 473/500\n",
            "17/17 - 0s - loss: 0.1005 - accuracy: 0.9516\n",
            "Epoch 474/500\n",
            "17/17 - 0s - loss: 0.1003 - accuracy: 0.9516\n",
            "Epoch 475/500\n",
            "17/17 - 0s - loss: 0.1002 - accuracy: 0.9536\n",
            "Epoch 476/500\n",
            "17/17 - 0s - loss: 0.0999 - accuracy: 0.9497\n",
            "Epoch 477/500\n",
            "17/17 - 0s - loss: 0.1001 - accuracy: 0.9478\n",
            "Epoch 478/500\n",
            "17/17 - 0s - loss: 0.0996 - accuracy: 0.9478\n",
            "Epoch 479/500\n",
            "17/17 - 0s - loss: 0.0994 - accuracy: 0.9497\n",
            "Epoch 480/500\n",
            "17/17 - 0s - loss: 0.0996 - accuracy: 0.9536\n",
            "Epoch 481/500\n",
            "17/17 - 0s - loss: 0.0992 - accuracy: 0.9516\n",
            "Epoch 482/500\n",
            "17/17 - 0s - loss: 0.0994 - accuracy: 0.9497\n",
            "Epoch 483/500\n",
            "17/17 - 0s - loss: 0.0993 - accuracy: 0.9497\n",
            "Epoch 484/500\n",
            "17/17 - 0s - loss: 0.0987 - accuracy: 0.9478\n",
            "Epoch 485/500\n",
            "17/17 - 0s - loss: 0.0983 - accuracy: 0.9420\n",
            "Epoch 486/500\n",
            "17/17 - 0s - loss: 0.0983 - accuracy: 0.9516\n",
            "Epoch 487/500\n",
            "17/17 - 0s - loss: 0.0980 - accuracy: 0.9497\n",
            "Epoch 488/500\n",
            "17/17 - 0s - loss: 0.0984 - accuracy: 0.9478\n",
            "Epoch 489/500\n",
            "17/17 - 0s - loss: 0.0986 - accuracy: 0.9516\n",
            "Epoch 490/500\n",
            "17/17 - 0s - loss: 0.0984 - accuracy: 0.9555\n",
            "Epoch 491/500\n",
            "17/17 - 0s - loss: 0.0976 - accuracy: 0.9516\n",
            "Epoch 492/500\n",
            "17/17 - 0s - loss: 0.0974 - accuracy: 0.9497\n",
            "Epoch 493/500\n",
            "17/17 - 0s - loss: 0.0987 - accuracy: 0.9536\n",
            "Epoch 494/500\n",
            "17/17 - 0s - loss: 0.0980 - accuracy: 0.9497\n",
            "Epoch 495/500\n",
            "17/17 - 0s - loss: 0.0971 - accuracy: 0.9536\n",
            "Epoch 496/500\n",
            "17/17 - 0s - loss: 0.0967 - accuracy: 0.9536\n",
            "Epoch 497/500\n",
            "17/17 - 0s - loss: 0.0965 - accuracy: 0.9574\n",
            "Epoch 498/500\n",
            "17/17 - 0s - loss: 0.0960 - accuracy: 0.9555\n",
            "Epoch 499/500\n",
            "17/17 - 0s - loss: 0.0961 - accuracy: 0.9536\n",
            "Epoch 500/500\n",
            "17/17 - 0s - loss: 0.0958 - accuracy: 0.9497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "jwagmpTiZ6K2",
        "outputId": "9bdd0680-2a58-41db-826c-fd39c5d6c541"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgzW-9r-boSl",
        "outputId": "edead46c-b83c-4c82-db15-9dd8ffcfd574"
      },
      "source": [
        "seed_text = \"Laurence arrived with\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequences_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print('\\n\\n',seed_text)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Laurence arrived with fainted and mcgilligan bacon and suppose three were entangled runctions girls and wall wall hearty water free suppose tea might ask ask jig polkas table ten mchugh jig jig polkas the athy hall your glisten glisten glisten call glisten glisten glisten glisten cried young hall hall hall hall hall hall athy hall eyes glisten glisten dublin glisten groups call groups eyes glisten water water water water water me water water me pound a ask ask mchugh mchugh invitation water boys brooks glisten call call glisten glisten cried murther eyes glisten water water water cask cask groups ground ten eyes rose\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}