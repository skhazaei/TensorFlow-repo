{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRJ7KlyMQCkKTeQPkxiRPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skhazaei/TensorFlow-repo/blob/master/metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGSR-IvXaD-"
      },
      "source": [
        "# Let's first build a sample model with `metrics=['accuracy']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppVupHsXM0u"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U9yRQ_xYt5y"
      },
      "source": [
        "model = Sequential([\n",
        "                    Flatten(input_shape=(28,28)),\n",
        "                    Dense(32, activation='relu'),\n",
        "                    Dense(32, activation='tanh'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEbD0SEdZFm2"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='Sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tTsTCcmZiHo"
      },
      "source": [
        "# `accuracy` as a metric to judge the performance of the model, how does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr0JnIPMaRjp"
      },
      "source": [
        "## **Case 1: Binary classification with sigmoid activation function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkKNdVGoaiwA"
      },
      "source": [
        "Let's suppose we are training a model for a binary classification problem. \n",
        "\n",
        "Given a training example input $x^{i}$, the model will output a float number between 0 and 1. Based on whether this float is less or higher than a threshold (which is by default at 0.5), we round the float number to get a value for $y_{pred}$ from the model. \n",
        "\n",
        "**The accuracy** metric compares the value of each $y_{pred}$ on each training example with its true value of one-hot coded vector $y_{true}^{(i)}$ from our training data:\n",
        "Let \n",
        "\n",
        "$$\n",
        "\\delta(y_{pred}^{(i)}, y_{true}^{(i)})=\n",
        "\\begin{cases}\n",
        "1 & y_{pred}=y_{true} \\\\\n",
        "0 & y_{pred}\\neq y_{true}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The **accuracy metric compute the mean value of** $\\delta(y_{pred}^{(i)}, y_{true}^{(i)})$ **over all training example:**\n",
        "\n",
        "$$accuracy = \\frac{1}{N}\\sum_{i=1}^{N} \\delta(y_{pred}^{(i)}, y_{true}^{(i)})$$\n",
        "\n",
        "The following is the implementation for an example in the backend of keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsPxdb6mZUbY",
        "outputId": "a7f15543-aace-4b11-a6ff-92bcf6d40e86"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow.keras.backend as K\n",
        "# Sigmoid activation function\n",
        "## tf.keras.backend.equal: Element-wise equality between two tensors.\n",
        "\n",
        "y_true = tf.constant([0.0,1.0,1.0])\n",
        "y_pred = tf.constant([0.4,0.8, 0.3])\n",
        "accuracy = K.mean(K.equal(y_true, K.round(y_pred)))\n",
        "accuracy"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.6666667>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtyUwyWLk8PG"
      },
      "source": [
        "## **Case 2: Categorical classification with softmax activation function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTi5xko1paKu"
      },
      "source": [
        "Now let's suppose that we are training a classification model that sorts out the data into m classes, $m>2$, using softmax function in the last layer.\n",
        "\n",
        "Given a training example $x^{(i)}$, the model outputs a tensor of probabilities $p_1, p_2, ..., p_m$, giving the likelihood that the  training examples belong into each class.\n",
        "\n",
        "The accuracy metric works by determining the largest argument in the $y_{pred}^{(i)}$ tensor, and compares its index to the index of the maximum value of $y_{true}^{(i)}$ to determine $\\delta(y_{pred}^{(i)}, y_{true}^{(i)})$. It then computes the accuracy in the same way as for the binary classification case.\n",
        "\n",
        "$$ accuracy = \\frac{1}{N} \\sum_{i=1}^N \\delta(y_{pred}^{(i)},y_{true}^{(i)}) $$\n",
        "\n",
        "The following is the implementation for an example in the backend of keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLGFA9VihII",
        "outputId": "f13e18bb-7e5a-4f71-b8ec-de064960210c"
      },
      "source": [
        "# Binary classification with softmax\n",
        "\n",
        "y_true = tf.constant([[0.0,1.0],[1.0,0.0],[1.0,0.0],[0.0,1.0]])\n",
        "y_pred = tf.constant([[0.4,0.6], [0.3,0.7], [0.05,0.95],[0.33,0.67]])\n",
        "accuracy =K.mean(K.equal(y_true, K.round(y_pred)))\n",
        "accuracy"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnZMCrTGseaz",
        "outputId": "d1b694ae-129d-4dcc-c9b8-8e943d13474f"
      },
      "source": [
        "# Categorical classification with m>2\n",
        "\n",
        "y_true = tf.constant([[0.0,1.0,0.0,0.0],[1.0,0.0,0.0,0.0],[0.0,0.0,1.0,0.0]])\n",
        "y_pred = tf.constant([[0.4,0.6,0.0,0.0], [0.3,0.2,0.1,0.4], [0.05,0.35,0.5,0.1]])\n",
        "accuracy = K.mean(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))\n",
        "accuracy"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.6666667>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-90ZAd7uM-k"
      },
      "source": [
        "# **`accuracy` vs. `binary_accuracy` vs. `categorical_accuracy`**\n",
        "\n",
        "the `binary_accuracy` and `categorical_accuracy` metrics are, by default identical to the case 1 and 2 respectively of the `accuracy` metric explained above.\n",
        "\n",
        "However, using `binary_accuracy` allows you to use the optional `threshold` argument, which sets the minimum value of $y_{pred}$ which will be rounded to 1. `threshold=0.5` is by default.\n",
        "\n",
        "```\n",
        "tf.keras.metrics.BinaryAccuracy(\n",
        "    name='binary_accuracy', dtype=None, threshold=0.5\n",
        ")\n",
        "```\n",
        "```\n",
        "tf.keras.metrics.CategoricalAccuracy(\n",
        "    name='categorical_accuracy', dtype=None\n",
        ")\n",
        "```\n",
        "\n",
        "Below we give some examples of how to compile a model with `binary_accuracy` with and without a threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltpuLx0ouMuZ"
      },
      "source": [
        "# Compile the model with default threshold (=0.5)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['binary_accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgaoKOMCtbAo"
      },
      "source": [
        "# The threshold can be specified as follows\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apPyCqlIwWMi"
      },
      "source": [
        "# Sparse categorical accuracy \n",
        "\n",
        "This is very similar metric to `categorical_accuracy` with one major difference - The label $y_{true}$ of each training example is not expected to be one-hot encoded vector, but to be a tensor consisting of a single integer. This integer is then compared to the index of the maximum argument of $y_{pred}$ to determine $\\delta(y_{pred}^{(i)},y_{true}^{(i)})$.\n",
        "\n",
        "```\n",
        "tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='sparse_categorical_accuracy', dtype=None\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTt0c8SRv_Ao"
      },
      "source": [
        "# Two examples of compiling a model with a sparse categorical accuracy metric\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQahLw47xmZn"
      },
      "source": [
        "# **(Sparse) Top $k$-categorical accuracy** :\n",
        "\n",
        "In top $k$-categorical accuracy, instead of computing how often the model correctly predicts the label of a training example, the metric computes how often the model has $y_{true}$ in the top $k$ of its predictions. By default, $k=5$.\n",
        "\n",
        "As before, the main difference between top $k$-categorical accuracy and its sparse version is that the former assumes $y_{true}$ is a one-hot encoded vector, whereas the sparse version assumes $y_{true}$ is an integer.\n",
        "\n",
        "```\n",
        "tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
        "    k=5, name='sparse_top_k_categorical_accuracy', dtype=None\n",
        ")\n",
        "```\n",
        "\n",
        "```\n",
        "tf.keras.metrics.TopKCategoricalAccuracy(\n",
        "    k=5, name='top_k_categorical_accuracy', dtype=None\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfhMUxTExbDZ"
      },
      "source": [
        "# Compile a model with a top-k categorical accuracy metric with default k (=5)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[\"top_k_categorical_accuracy\"])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RE_9fNkyHxh"
      },
      "source": [
        "# Specify k instead with the sparse top-k categorical accuracy\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AibmC1lhz0DK"
      },
      "source": [
        "## Custom metrics\n",
        "It is also possible to define your own custom metric in Keras.\n",
        "You will need to make sure that your metric takes in (at least) two arguments called `y_true` and `y_pred` and then output a single tensor value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_OykrlnyK3f"
      },
      "source": [
        "# Define a custom metric\n",
        "\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz1zxRf4z6IV"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[mean_pred])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvBcmjD0Gr5"
      },
      "source": [
        "## Multiple metrics\n",
        "Finally, it is possible to use multiple metrics to judge the performance of your model. \n",
        "\n",
        "\n",
        "Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDSb9xBuz-cm"
      },
      "source": [
        "# Compile the model with multiple metrics\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[mean_pred,\n",
        "                       'accuracy',\n",
        "                       tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}